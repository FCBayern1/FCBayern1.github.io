<!DOCTYPE html>


<html lang="en">
  

    <head>
      <meta charset="utf-8" />
        
      <meta name="description" content="joshua" />
      
      <meta
        name="viewport"
        content="width=device-width, initial-scale=1, maximum-scale=1"
      />
      <title>webscience |  Mingwei’s Blog</title>
  <meta name="generator" content="hexo-theme-ayer">
      
      <link rel="shortcut icon" href="/favicon.ico" />
       
<link rel="stylesheet" href="/dist/main.css">

      
<link rel="stylesheet" href="/css/fonts/remixicon.css">

      
<link rel="stylesheet" href="/css/custom.css">
 
      <script src="https://cdn.staticfile.org/pace/1.2.4/pace.min.js"></script>
       
 

      <link
        rel="stylesheet"
        href="https://cdn.jsdelivr.net/npm/@sweetalert2/theme-bulma@5.0.1/bulma.min.css"
      />
      <script src="https://cdn.jsdelivr.net/npm/sweetalert2@11.0.19/dist/sweetalert2.min.js"></script>

      <!-- mermaid -->
      
      <style>
        .swal2-styled.swal2-confirm {
          font-size: 1.6rem;
        }
      </style>
    </head>
  </html>
</html>


<body>
  <div id="app">
    
      
    <main class="content on">
      <section class="outer">
  <article
  id="post-webscience"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h1 class="article-title sea-center" style="border-left:0" itemprop="name">
  webscience
</h1>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2023/04/28/webscience/" class="article-date">
  <time datetime="2023-04-28T12:34:43.000Z" itemprop="datePublished">2023-04-28</time>
</a>   
<div class="word_count">
    <span class="post-time">
        <span class="post-meta-item-icon">
            <i class="ri-quill-pen-line"></i>
            <span class="post-meta-item-text"> Word count:</span>
            <span class="post-count">7.2k</span>
        </span>
    </span>

    <span class="post-time">
        &nbsp; | &nbsp;
        <span class="post-meta-item-icon">
            <i class="ri-book-open-line"></i>
            <span class="post-meta-item-text"> Reading time≈</span>
            <span class="post-count">45 min</span>
        </span>
    </span>
</div>
 
    </div>
      
    <div class="tocbot"></div>




  
    <div class="article-entry" itemprop="articleBody">
       
  <h1 id="Revision"><a href="#Revision" class="headerlink" title="Revision"></a>Revision</h1><h2 id="Topic-1-Social-Media-Twitter-Crawl"><a href="#Topic-1-Social-Media-Twitter-Crawl" class="headerlink" title="Topic 1- Social Media (Twitter) Crawl"></a>Topic 1- Social Media (Twitter) Crawl</h2><h3 id="L1-TwitterData"><a href="#L1-TwitterData" class="headerlink" title="L1 TwitterData"></a>L1 TwitterData</h3><h4 id="Exploitation-of-the-twitter-data"><a href="#Exploitation-of-the-twitter-data" class="headerlink" title="Exploitation of the twitter data:"></a>Exploitation of the twitter data:</h4><p>With the amount of content posted to social media websites every day, such as Twitter, there is huge potential for its exploitation in many scenarios, such as:</p>
<p><strong>Sports and Finance:</strong> Stock market prediction &amp; Sports betting</p>
<p>predict stock market changes based on the sentiment of tweets</p>
<ul>
<li>Sentiment expressed in tweets had been used to predict stock market reactions</li>
<li>Opinions of investors’ posts on social media</li>
<li>combine with the stock prize movements</li>
</ul>
<p>Sports betting</p>
<h4 id="Web-Science-Concepts"><a href="#Web-Science-Concepts" class="headerlink" title="Web Science Concepts"></a>Web Science Concepts</h4><ul>
<li><p>﻿﻿Explore the science underlying the web</p>
<ul>
<li>﻿﻿From a socio-technical perspective</li>
<li>﻿﻿Mathematical properties, engineering principles, social impacts</li>
</ul>
</li>
<li><p>﻿﻿Understanding users and developing Web applications for them!</p>
<ul>
<li>﻿﻿Sociology &amp; Web Engineering</li>
</ul>
</li>
<li><p>﻿﻿Consulting corporations about social media activities</p>
<ul>
<li>﻿﻿Economics &amp; Web analvtics</li>
<li>﻿﻿For example, role of micro influencers on local economy</li>
<li>﻿﻿How much hate a brand page generates due to some comments, ….</li>
</ul>
</li>
<li><p>﻿﻿Data analvtics</p>
<ul>
<li>﻿﻿Growth of information; structured and unstructured</li>
<li>﻿﻿Intersection of networks &amp; data</li>
</ul>
</li>
<li><p>Broble mew technologies to scientists and engineers working together on large scale</p>
</li>
</ul>
<h3 id="L2-DataClustering"><a href="#L2-DataClustering" class="headerlink" title="L2 DataClustering"></a>L2 DataClustering</h3><h4 id="Content-processing"><a href="#Content-processing" class="headerlink" title="Content processing"></a>Content processing</h4><h4 id="1-Removing-stuff"><a href="#1-Removing-stuff" class="headerlink" title="1. Removing stuff"></a>1. Removing stuff</h4><ul>
<li>Non-ascii removal</li>
</ul>
<p>remove the emoji…</p>
<p>![image-20230429103013009](..&#x2F;images&#x2F;webs&#x2F;:Users:joshua:Library:Application Support:typora-user-images:image-20230429103013009.png)</p>
<h4 id="2-Grouping-tweets"><a href="#2-Grouping-tweets" class="headerlink" title="2. Grouping tweets"></a>2. Grouping tweets</h4><ul>
<li>﻿﻿Based on content analysis like<ul>
<li>﻿﻿Clustering, locality sensitive hashing</li>
<li>﻿﻿Or through content indexes</li>
</ul>
</li>
<li>﻿﻿Once we know the groups<ul>
<li>﻿﻿We could analyse the words, user mentions, hashtags in these groups</li>
<li>﻿﻿We can add these terms to a list with a priority</li>
<li>﻿﻿This is possibly for identifying more tweets of this type<ul>
<li>﻿﻿Aim is data gathering</li>
</ul>
</li>
</ul>
</li>
<li>﻿﻿We can also look at proficient tweeters<ul>
<li>﻿﻿What are their total tweets</li>
</ul>
</li>
</ul>
<h4 id="3-Tokenization"><a href="#3-Tokenization" class="headerlink" title="3. Tokenization"></a>3. Tokenization</h4><p>Separate each token</p>
<p>Remove stopwords</p>
<h4 id="4-Vector-Representation"><a href="#4-Vector-Representation" class="headerlink" title="4. Vector Representation"></a>4. Vector Representation</h4><p>Documents are represented by a term vector</p>
<p><em>Di</em> &#x3D; (ti1,ti2 ,….,tin )</p>
<p>Queries are represented by a similar vector</p>
<p>• In binary scheme, tik is set to 1 when term k is present in Document i otherwise they are set to zero</p>
<ul>
<li>The most relevant documents for a query are expected to be those represented by the vectors closest to the query, that is documents that use similar words to the query.</li>
<li>﻿﻿Closeness is often calculated by just looking at angles between document vector and query vector</li>
<li>﻿﻿We need a similarity measure!<ul>
<li>Cosine similarity measure</li>
<li>Jaccard coefficient</li>
<li>Dice coefficient</li>
</ul>
</li>
</ul>
<h4 id="Finding-similar-tweets-Single-pass-clustering"><a href="#Finding-similar-tweets-Single-pass-clustering" class="headerlink" title="Finding similar tweets Single-pass clustering"></a>Finding similar tweets Single-pass clustering</h4><p><strong>Single-pass clustering</strong></p>
<ul>
<li><p>requires a single, sequential pass over the set of documents it attempts to cluster.</p>
</li>
<li><h4 id="The-algorithm-classifies-the-next-document-in-the-sequence-according-to-a-condition-on-the-similarity-function-employed"><a href="#The-algorithm-classifies-the-next-document-in-the-sequence-according-to-a-condition-on-the-similarity-function-employed" class="headerlink" title="The algorithm classifies the next document in the sequence according to a condition on the similarity function employed."></a>The algorithm classifies the next document in the sequence according to a condition on the similarity function employed.</h4></li>
<li><p>At every stage, <strong>the algorithm decides on whether a newly seen document should become a member of an already defined cluster or the centre of a new one.</strong></p>
<ul>
<li>In its most simple form, the similarity function gets defined on the basis of just some similarity (or alternatively, dissimilarity) measure between document-feature vectors.</li>
</ul>
</li>
</ul>
<p>![image-20230429121645868](..&#x2F;images&#x2F;webs&#x2F;:Users:joshua:Library:Application Support:typora-user-images:image-20230429121645868.png)</p>
<p>Comments on Single Pass Method</p>
<ul>
<li>﻿﻿The single pass method is particularly simple<ul>
<li>﻿﻿since it requires that the data set be processed only once.</li>
</ul>
</li>
<li>﻿﻿Obviously, the results for this method are highly dependent on the similarity threshold that is used.</li>
<li>﻿﻿It tends to produce large clusters early in the clustering pass,<ul>
<li>﻿﻿and because the clusters formed are not independent of the order in which the data set is processed.</li>
<li>﻿﻿You should use your judgment in setting this threshold so that you are left with a reasonable number of clusters.</li>
</ul>
</li>
<li>﻿﻿It is sometimes used to form the groups that are used to initiate reallocation clustering.<ul>
<li>﻿﻿If we get a large noisy clusters of tweets, we could re-cluster them!!!</li>
</ul>
</li>
</ul>
<h3 id="L3-Credibility-amp-Newsworthiness"><a href="#L3-Credibility-amp-Newsworthiness" class="headerlink" title="L3 Credibility &amp; Newsworthiness"></a>L3 Credibility &amp; Newsworthiness</h3><h4 id="Newsworthy"><a href="#Newsworthy" class="headerlink" title="Newsworthy"></a><strong>Newsworthy</strong></h4><p>Key characteristics of newsworthy score</p>
<ul>
<li>﻿﻿Real-time<ul>
<li>﻿﻿Tweets should be scored as soon as it arrives!</li>
</ul>
</li>
<li>﻿﻿Generalizability<ul>
<li>﻿﻿Should be able to handle any types of events - not those just seen before</li>
</ul>
</li>
<li>﻿﻿Adaptive<ul>
<li>﻿﻿New information to be incorporated, as and when they arrive</li>
<li>﻿﻿Incorporate new information to the scoring model</li>
</ul>
</li>
</ul>
<p>These characteristics should be realized with the help of <strong>classification approach</strong> and <strong>distant supervision</strong>.</p>
<h4 id="HeurisIc-Labelling"><a href="#HeurisIc-Labelling" class="headerlink" title="HeurisIc Labelling"></a><strong>HeurisIc Labelling</strong></h4><ul>
<li>﻿﻿Semi-automatic labelling approach<ul>
<li>﻿﻿Using a set of heuristics to label<ul>
<li>﻿﻿High quality (newsworthy) and low quality (noisy) content</li>
</ul>
</li>
</ul>
</li>
<li>﻿﻿This will not label majority of the content</li>
<li>﻿﻿Advantages<ul>
<li>﻿﻿Minimal effort in creating a data set</li>
<li>﻿﻿Real-life data set - incremental and generalizable</li>
<li>﻿﻿Easily built as part of an algorithm for example event detection</li>
</ul>
</li>
</ul>
<p><strong>Overall approach</strong></p>
<ul>
<li><p>Collect a set of high-quality sets and low-quality sets of data</p>
</li>
<li><p>Use this dataset to potentially score a newsworthy tweet</p>
</li>
</ul>
<h4 id="Quality-Score"><a href="#Quality-Score" class="headerlink" title="Quality Score"></a>Quality Score</h4><p>Quality Score &#x3D; (profileWeight + verifiedWeight + followers Weight + accountAgeWeight + descriptionWeight)&#x2F;5</p>
<p>Range is [0 to 1]</p>
<p>if q score is higher than 0.65 -&gt; high quality </p>
<p>if q score is lower than 0.45 -&gt; low quality</p>
<h4 id="Scoring-model"><a href="#Scoring-model" class="headerlink" title="Scoring model"></a>Scoring model</h4><p>Likelihood ratio for each term</p>
<ul>
<li>﻿﻿R(t) &#x3D; relative importance of term in the particular quality model when compared to random background model</li>
<li>﻿﻿&gt;1<ul>
<li>﻿Term is more common in the model than random</li>
</ul>
</li>
<li>﻿﻿&lt;1<ul>
<li>﻿﻿Term is less common in the model than random</li>
</ul>
</li>
</ul>
<p>![image-20230429134512747](..&#x2F;images&#x2F;webs&#x2F;:Users:joshua:Library:Application Support:typora-user-images:image-20230429134512747.png)</p>
<p><strong>cntd</strong></p>
<p>if RHQ(t)&lt;2 or RLQ(t)&lt;2 then the Score will be set 0 as to remove the terms which have no clear association with either high quality content or low-quality content.</p>
<p>![image-20230429134931099](..&#x2F;images&#x2F;webs&#x2F;:Users:joshua:Library:Application Support:typora-user-images:image-20230429134931099.png)</p>
<h3 id="L4-Geo-localisation"><a href="#L4-Geo-localisation" class="headerlink" title="L4-Geo-localisation"></a>L4-Geo-localisation</h3><h4 id="Fine-grained-localization"><a href="#Fine-grained-localization" class="headerlink" title="Fine-grained localization"></a>Fine-grained localization</h4><p>Fine-grained localization refers to the task of accurately localizing objects or entities within an image or a video with high precision, usually at a sub-pixel or sub-object level. This involves identifying the precise location of the object, as well as any associated attributes such as shape, texture, and color.</p>
<p>The goal of fine-grained localization is to provide more detailed and accurate information about the location and properties of objects in an image, which can be useful for a range of applications such as object tracking, object recognition, and scene understanding.</p>
<p>Fine-grained localization can be challenging due to the variability in object appearance, pose, and scale. To overcome these challenges, various techniques such as deep learning and computer vision algorithms have been developed.</p>
<p>Examples of fine-grained localization tasks include localizing individual bird species in a bird-watching image, identifying specific car models in a crowded parking lot, or detecting the presence of a particular species of fish in an underwater video.</p>
<p><strong>Problem statement</strong></p>
<ul>
<li>﻿﻿Geo-localization<ul>
<li>﻿﻿Provide location estimates for individual tweets</li>
</ul>
</li>
<li>﻿﻿coarse-grained Geo-localization<ul>
<li>﻿﻿Provide location estimates for individual tweets at regional or country level</li>
</ul>
</li>
<li>﻿﻿fine-grained Geo-localization<ul>
<li>﻿﻿Provide location estimates for individual tweets at city or neighbourhood level</li>
</ul>
</li>
<li>﻿﻿Approach<ul>
<li>﻿﻿Train a model on a geo-tagged data set<ul>
<li>﻿﻿Validate and test on geo-tagged data</li>
<li>﻿﻿Test on non-geo tagged data as well</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="Topic3-Topic-modelling"><a href="#Topic3-Topic-modelling" class="headerlink" title="Topic3 Topic modelling"></a>Topic3 Topic modelling</h2><h3 id="Topic-modelling"><a href="#Topic-modelling" class="headerlink" title="Topic modelling"></a>Topic modelling</h3><h4 id="Discuss-why-searching-is-limited-when-exploring-a-collection"><a href="#Discuss-why-searching-is-limited-when-exploring-a-collection" class="headerlink" title="Discuss why searching is limited when exploring a collection"></a><strong>Discuss why searching is limited when exploring a collection</strong></h4><p>When exploring a collection, searching can be limited by various factors such as the completeness and accuracy of the metadata, the complexity of the query, and the quality of the search algorithm.</p>
<p>Firstly, the completeness and accuracy of the metadata associated with each item in the collection can limit the effectiveness of searching. If the metadata is incomplete or inconsistent, important information about an item may not be captured, making it difficult or impossible to find through search queries.</p>
<p>Secondly, the complexity of the search query can also limit the effectiveness of searching. For example, if a user is looking for items that have multiple attributes or characteristics, such as a specific color and shape, the search query may become too complex and difficult to execute accurately.</p>
<p>Finally, the quality of the search algorithm used to explore the collection can also limit the effectiveness of searching. If the algorithm is not designed to handle the specific characteristics of the collection or the query, it may return irrelevant or incomplete results.</p>
<p>To overcome these limitations, various techniques can be employed such as using natural language processing to simplify complex search queries, improving the quality and completeness of metadata through manual curation or machine learning techniques, and using advanced search algorithms that take into account the specific characteristics of the collection and query.</p>
<p>Topic modelling is the process of using a topic model to discover the <strong>hidden topics</strong> that are represented by a large collection of documents</p>
<ul>
<li><p>Observed</p>
<ul>
<li><p>﻿﻿collection</p>
</li>
<li><p>﻿﻿Document &amp; words</p>
</li>
</ul>
</li>
<li><p>﻿﻿Aim</p>
<ul>
<li>﻿﻿Use the observed information to infer<ul>
<li>﻿﻿Hidden structure</li>
</ul>
</li>
</ul>
</li>
<li><p>﻿﻿Topic structure - hidden</p>
<ul>
<li>﻿﻿per document topic distributions</li>
<li>﻿﻿Per document per-word topic assignments<ul>
<li>﻿﻿Annotation…</li>
<li>﻿﻿Can be used for retrieval, classification, browsing?</li>
</ul>
</li>
</ul>
</li>
<li><p>﻿﻿Utility</p>
<ul>
<li>﻿﻿Inferred hidden structure resembles the thematic structure of the collection</li>
</ul>
</li>
</ul>
<p><strong>latent</strong></p>
<p>(of a quality or state) existing but not yet developed or manifest hidden or concealed.;</p>
<p>Topic modelling </p>
<ul>
<li>A machine learning approach for Mining latent topics</li>
</ul>
<p>Identify hidden, gigantic structures</p>
<p>Probabilistic topic models</p>
<ul>
<li>a suite of algorithms that aim to discover and annotate large archives of documents of thematic information</li>
</ul>
<h4 id="Our-goal-in-topic-modelling"><a href="#Our-goal-in-topic-modelling" class="headerlink" title="Our goal in topic modelling"></a>Our goal in topic modelling</h4><ul>
<li>﻿﻿The goal of topic modeling is to automatically discover the topics in a collection of documents</li>
<li>﻿﻿Documents are observed<ul>
<li>﻿﻿Topics, per-document and per-word topic assignments - hidden</li>
<li>﻿﻿Hence latent!</li>
</ul>
</li>
<li>﻿﻿The central computation problem for topic modelling is to use the observed documents to infer hidden topic structure</li>
<li>﻿﻿Think it as reversing the generative process<ul>
<li>﻿﻿What is the hidden structure that likely generated the observed collection?</li>
</ul>
</li>
</ul>
<h4 id="LDA-Latent-Dirichlet-Allocation"><a href="#LDA-Latent-Dirichlet-Allocation" class="headerlink" title="LDA (Latent Dirichlet Allocation)"></a>LDA (Latent Dirichlet Allocation)</h4><ul>
<li><p>﻿﻿Is a statistical model of document collections that tries to capture the intuition<br> Each document can be described by a distribution of topics and each topic can be described by a distribution of words</p>
</li>
<li><p>﻿﻿Topic</p>
<ul>
<li><p>﻿﻿Defined as a distribution over the words&#x2F; fixed vocabulary</p>
<ul>
<li><p>E.g., genetic topic has words about genetics (sequenced, genes) with high probability</p>
</li>
<li><p>﻿﻿Evolutionary biology has words like life, organism with high probability</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="Topic-Modelling-Approaches"><a href="#Topic-Modelling-Approaches" class="headerlink" title="Topic Modelling Approaches"></a>Topic Modelling Approaches</h4><ul>
<li>Number of possible topic structures is exponentially large</li>
<li>Approximate the posterior distribution</li>
<li>Topic modelling algorithms form an approximation of equation, <ul>
<li>by adapting an alternative distribution over latent topic structure to be close to the true posterior</li>
</ul>
</li>
</ul>
<p>Two approaches:</p>
<p><strong>1. Sampling based!</strong></p>
<p>Attempt to collect samples from the posterior to approximate it with an empirical distribution <strong>– Gibbs sampling!</strong></p>
<p><strong>2. Variational methods!</strong></p>
<p>Deterministic alternative to sampling based methods</p>
<p>Posit a parametrised family of distributions over the hidden structure and then find the member of that family that is closest to the posterior</p>
<p><strong>Summary</strong></p>
<p>The user specifies that there are K distinct topics</p>
<p>​	Each of the K topics is drawn from a aDirchlet distribution</p>
<p>​		Uniform base distribution (u) and concentration parameter B</p>
<p>​		theta_k ~ Dir(Bu)</p>
<p>Distributions over topics of each document 	theta_d ~ Dir (au)</p>
<ul>
<li>﻿﻿Topic assignment Z_d,n ~ Discrete(theta_d)</li>
<li>﻿Wd,n~theta_Z(d,n)</li>
</ul>
<p><strong>Sampling based!</strong></p>
<p>Attempt to collect samples from the posterior to approximate it with an empirical distribution - <strong>Gibbs sampling!</strong></p>
<p><strong>Variational methods!</strong></p>
<p>Deterministic alternative to sampling based methods</p>
<p>Posit a parametrised family of distributions over the hidden structure and then find the member of that family that is closest to the posterior</p>
<p><strong>Gibbs Sampling</strong></p>
<p>It generates samples from complex, high-dimensional probability distributions.</p>
<p>The algorithm for Gibbs sampling is as follows:</p>
<ol>
<li>Initialize each variable with an initial value.</li>
<li>Choose a variable to update, say the i-th variable.</li>
<li>Sample a new value for the i-th variable from its conditional distribution, given the current values of the other variables.</li>
<li>Repeat steps 2 and 3 for a specified number of iterations or until convergence is achieved.</li>
</ol>
<h4 id="LDA"><a href="#LDA" class="headerlink" title="LDA"></a><strong>LDA</strong></h4><ul>
<li><p>﻿﻿LDA is a probabilistic generative model</p>
<ul>
<li>﻿﻿Each document is a distribution of topics</li>
<li>﻿﻿Each topic is a distribution of words</li>
</ul>
</li>
<li><p>﻿﻿Sample a topic from a document-level topic distribution</p>
<ul>
<li>﻿﻿That obeys Dirichlet distribution</li>
</ul>
</li>
<li><p>﻿﻿Then sample a words according to the topic distribution of this topic</p>
<ul>
<li>﻿﻿Dirichlet distribution</li>
</ul>
</li>
<li><p>﻿﻿Generate a document</p>
</li>
<li><p>﻿﻿Hence, LDA implicitly model document level word co-occurrence pattern</p>
</li>
<li><p>﻿﻿Sparsity problem exacerbates performance issues</p>
<ul>
<li>﻿﻿The limited contexts make it more difficult for topic models to identify the senses of ambiguous words in short documents.</li>
</ul>
</li>
<li><p>﻿﻿Short documents like Tweet</p>
<ul>
<li>﻿﻿Sparse words …</li>
<li>﻿﻿Time-sensitive</li>
<li>﻿﻿Lack of clear context because not much information; no formal structure<ul>
<li>﻿﻿How words are related often measured through co-occurrence patterns</li>
<li>﻿﻿In short texts document-level co-occurrence patterns are difficult to capture</li>
</ul>
</li>
</ul>
</li>
<li><p>﻿﻿Massive volume of tweet;</p>
<ul>
<li>﻿﻿Memory requirements</li>
</ul>
</li>
<li><p>﻿﻿Real-time nature</p>
</li>
</ul>
<p>Problem with LDA to train twitter</p>
<p><strong>Why not LDA?</strong></p>
<ul>
<li>LDA needs to be trained on the entire data sets<ul>
<li>Memory requirements for the model</li>
</ul>
</li>
<li>LDA is trained and tested on a data set<ul>
<li>Time-sensitive nature of Twitter</li>
</ul>
</li>
</ul>
<p>How to address this issue …?</p>
<ul>
<li>﻿﻿Enrich the word co -occurrence information<ul>
<li>﻿﻿To enrich the limited word co -occurrence information contained in a single short text,</li>
</ul>
</li>
<li>﻿﻿Make larger texts by grouping short texts (tweets)<ul>
<li>﻿﻿Grouping tweets by the authors</li>
<li>﻿﻿However, this aggregation method highly depends on the meta - information of each text,<ul>
<li>﻿﻿which may not always be available for many kinds of short texts.</li>
</ul>
</li>
<li>﻿﻿Another strategy models the similarity between texts to aggregate similar texts into a long pseudo -document</li>
</ul>
</li>
<li>﻿﻿Explicit text similarity</li>
</ul>
<h2 id="Topic4-Network-Analysis"><a href="#Topic4-Network-Analysis" class="headerlink" title="Topic4 Network Analysis"></a>Topic4 Network Analysis</h2><h3 id="L6-Graph-based-Network-Analysis"><a href="#L6-Graph-based-Network-Analysis" class="headerlink" title="L6 Graph-based Network Analysis"></a>L6 Graph-based Network Analysis</h3><h4 id="Graph-Modelling"><a href="#Graph-Modelling" class="headerlink" title="Graph Modelling"></a>Graph Modelling</h4><ul>
<li>﻿﻿Capturing structural properties of social networks</li>
<li>﻿﻿Relationships formed between individuals<ul>
<li>﻿﻿To identify clusters</li>
<li>﻿﻿Cliques and connected components of users</li>
<li>﻿﻿Centrality measures</li>
</ul>
</li>
<li>﻿﻿Hashtags<ul>
<li>﻿﻿Which hashtags are strongly connected</li>
</ul>
</li>
</ul>
<p><strong>Centrality Measures:</strong> Find the influential users, find the centre of a graph.</p>
<p><strong>Why graph?</strong></p>
<ul>
<li><p>﻿﻿By analyzing network data, we can ask many questions</p>
<ul>
<li>﻿﻿Who is most important in a network?</li>
<li>﻿﻿Which way information flows?</li>
</ul>
</li>
<li><p>﻿﻿We can use graph analysis to answer questions like these</p>
</li>
<li><p>﻿﻿Note</p>
<ul>
<li>﻿﻿Sample questions!</li>
<li>﻿﻿What are people talking about?<br> How are they responding to a product?</li>
<li>﻿﻿The breadth of such analyses is huge and not covered fully</li>
</ul>
</li>
</ul>
<h4 id="Graph-Theory"><a href="#Graph-Theory" class="headerlink" title="Graph Theory"></a><strong>Graph Theory</strong></h4><p><strong>Graph</strong></p>
<ul>
<li><p>﻿﻿Graphs are way to formally represent a network or a set of interconnected objects</p>
</li>
<li><p>﻿﻿Nodes and edges</p>
</li>
<li><p>﻿﻿Unlike trees no concept of root node, In the graph, there is no unique node which is known as root.</p>
</li>
<li><p>﻿﻿One node might be connected to five others!</p>
</li>
<li><p>﻿﻿No concept one-directional flow!</p>
</li>
</ul>
<p>﻿﻿<strong>Edges</strong></p>
<ul>
<li>﻿﻿With direction or flow!</li>
<li>﻿﻿Without direction!</li>
</ul>
<p><strong>Direction</strong></p>
<ul>
<li>﻿﻿Origin to destination</li>
</ul>
<p><strong>Trees vs graphs</strong></p>
<p>A tree is a set of nodes and edges. In a tree, there is a unique node which is known as root.</p>
<p>Terminology - <strong>Undirected</strong> graphs</p>
<ul>
<li>﻿﻿u and v are adjacent if {u, v} is an edge,<ul>
<li>﻿﻿e is called incident with u and v</li>
<li>﻿﻿u and v are called endpoints of {u, v}</li>
</ul>
</li>
<li>﻿﻿Degree of Vertex (deg (V)):<ul>
<li>﻿﻿the number of edges incident on a vertex.</li>
<li>﻿﻿<strong>A loop contributes twice to the degree</strong></li>
</ul>
</li>
</ul>
<p>Terminology - <strong>Directed</strong> graphs</p>
<ul>
<li>﻿﻿For the edge (u, v), u is adjacent to v OR v is adjacent from u,</li>
<li>﻿﻿u - Initial vertex origin)</li>
<li>﻿﻿v - Terminal vertex destination)</li>
<li>﻿﻿In-degree (deg (u)): number of edges for which u is terminal vertex</li>
<li>﻿﻿Out-degree (deg+ (u)): number of edges for which u is initial vertex</li>
</ul>
<p><strong>Incidence Matrix:</strong></p>
<p>What are the maximum potential edges?</p>
<p>Undirected graph: (n*(n-1))&#x2F;2</p>
<p>Directed graph (n*(n-1))</p>
<p>Edge density &#x3D; no of edges&#x2F; max no of edges possible</p>
<p><strong>Adjacency Matrix</strong></p>
<ul>
<li><p>﻿﻿There is an N x N matrix, where |V| &#x3D; N,</p>
</li>
<li><p>﻿﻿the Adjacenct Matrix (N×N)</p>
</li>
<li><p>﻿﻿This makes it easier to find subgraphs</p>
</li>
<li><p>﻿﻿When there are relatively few edges in the graph the adjacency matrix is a sparse matrix</p>
</li>
</ul>
<h4 id="Graph-analysis-in-twitter"><a href="#Graph-analysis-in-twitter" class="headerlink" title="Graph analysis in twitter"></a>Graph analysis in twitter</h4><p>Twitter is directed graph while facebook is undirected</p>
<p><strong>Why graph analysis?</strong></p>
<ul>
<li>﻿﻿By analyzing tweet data, we can ask many questions</li>
<li>﻿﻿Who is most important in a network?</li>
<li>﻿﻿How did the information flow?</li>
<li>﻿﻿How could we reach 50% of the graph?</li>
<li>﻿﻿Who is more influential?</li>
<li>﻿﻿What are people talking about?</li>
<li>﻿﻿How are they responding to a product?</li>
</ul>
<p><strong>Centrality</strong></p>
<p>find who is important</p>
<ul>
<li>Measures of importance in social networks are called centrality measures</li>
</ul>
<p><strong>Degree centrality</strong></p>
<ul>
<li><p>Who gets the most re-tweets?</p>
<ul>
<li>Basically says who is most important in the network</li>
</ul>
</li>
<li><p>In-degree: number of retweets of a user</p>
</li>
<li><p>Out-degree: number of retweets this particular user made</p>
</li>
<li><p>﻿﻿The degree centrality is a fundamental metric in network analysis.</p>
</li>
<li><p>﻿﻿It is used to directly quantify the number of nodes in the network that a given node is adjacent to.</p>
</li>
<li><p>﻿﻿for directed networks</p>
<ul>
<li>﻿﻿There are variations of this metric that are used, where connections between nodes have a directionality.</li>
</ul>
</li>
<li><p>﻿﻿In directed networks, it makes sense to talk about the following:</p>
</li>
<li><p>﻿﻿In-degree - For a given node, how many edges are incoming to the node.<br> the node.</p>
</li>
<li><p>﻿Out-degree - For a given node, how many edges are outgoing from</p>
</li>
<li><p>﻿﻿CD(v) &#x3D; deg(v)</p>
</li>
</ul>
<p><strong>Centrality measures!</strong></p>
<p>Designed to characterise</p>
<ul>
<li>﻿﻿Functional role - what part does this node play in system dynamics?</li>
<li>﻿﻿Structural importance - how important is this node to the structural characteristics of the system?</li>
</ul>
<p>In each of the following networks, X has higher centrality than Y according to a particular measure</p>
<p>![image-20230430204648900](..&#x2F;images&#x2F;webs&#x2F;:Users:joshua:Library:Application Support:typora-user-images:image-20230430204648900.png)</p>
<ul>
<li>﻿﻿“Who is the most important or central person in this network?”<ul>
<li>﻿﻿There are many answers to this question, depending on what we mean by importance.</li>
</ul>
</li>
<li>﻿﻿The power a person holds in the organization is inversely proportional to the number of keys on his keyring.<ul>
<li>﻿﻿A janitor has keys to every office, and no power.</li>
<li>﻿﻿The CEO does not need a key: people always open the door for him.</li>
</ul>
</li>
<li>﻿﻿Degree centrality of a vertex</li>
</ul>
<p>![image-20230430205230578](..&#x2F;images&#x2F;webs&#x2F;:Users:joshua:Library:Application Support:typora-user-images:image-20230430205230578.png)</p>
<p>![image-20230430210025438](..&#x2F;images&#x2F;webs&#x2F;:Users:joshua:Library:Application Support:typora-user-images:image-20230430210025438.png)</p>
<p>Eigenvector centrality</p>
<ul>
<li><p>﻿﻿Who is the most influential</p>
</li>
<li><p>﻿﻿In contrast to degree centrality</p>
<ul>
<li>﻿﻿How important are these retweeters?</li>
</ul>
</li>
<li><p>﻿﻿is a measure of the influence of a node</p>
<ul>
<li>﻿﻿It assigns relative scores to all nodes in the network based on the concept that</li>
<li>﻿﻿connections to high-scoring nodes contribute more to the score of the node in<br> question<ul>
<li>﻿﻿than equal connections to low-scoring nodes.</li>
</ul>
</li>
</ul>
</li>
<li><p>﻿﻿Google’s page rank is variant of the eigenvector centrality.</p>
</li>
<li><p>﻿﻿Using Adjacency network</p>
<ul>
<li>﻿﻿Ax &#x3D; lambda x</li>
<li>﻿﻿there is a unique largest eigenvalue, which is real and positive,</li>
<li>﻿﻿This greatest eigenvalue results in the desired centrality measure.</li>
</ul>
</li>
</ul>
<p>Betweenness Centrality&#x2F;Closeness Centrality</p>
<p><strong>Betweenness centrality</strong> measures the number shortest paths in which the user is in the sequence of nodes in the path.</p>
<ul>
<li>It was introduced as a measure for quantifying the control of a human on the communication between other humans in social network.</li>
<li>In this conception, vertices that have a high probability to occur on a randomly chosen shortest path between two randomly chosen vertices have a high betweenness.</li>
</ul>
<p>![image-20230430213515337](..&#x2F;images&#x2F;webs&#x2F;:Users:joshua:Library:Application Support:typora-user-images:image-20230430213515337.png)</p>
<p>Closeness Centrality: Definition</p>
<ul>
<li>﻿﻿Closeness is based on the length of the average shortest path between a vertex and all vertices in the graph</li>
<li>﻿﻿Closeness Centrality</li>
</ul>
<h3 id="L7-Retweet-Graph-Trend-amp-Influencers"><a href="#L7-Retweet-Graph-Trend-amp-Influencers" class="headerlink" title="L7_Retweet Graph Trend &amp; Influencers"></a>L7_Retweet Graph Trend &amp; Influencers</h3><p>Information diffusion ….</p>
<p>tracing, understanding and predicting how </p>
<p>a piece of information is spreading. </p>
<h4 id="Information-diffusion"><a href="#Information-diffusion" class="headerlink" title="Information diffusion"></a>Information diffusion</h4><ul>
<li><p>in online communities, tracking the information diffusion is useful for many applications, for example,</p>
<ul>
<li>﻿﻿such as early warning systems,</li>
<li>﻿﻿social bot and community detection,</li>
<li>﻿﻿user location prediction,</li>
<li>﻿﻿financial recommendations,</li>
<li>﻿﻿marketing campaign effectiveness,</li>
<li>﻿﻿political mobilization and protests</li>
</ul>
</li>
<li><p>﻿﻿Twitter offers four possible actions to express interest in specific content:</p>
<ul>
<li>﻿﻿<strong>favorite</strong>, <strong>reply</strong>, <strong>quote</strong> and <strong>retweet</strong>.</li>
<li>﻿﻿Replying or liking a tweet does not involve the spread of the content,</li>
<li>﻿﻿whereas quotes and retweets are actions used to<ul>
<li>﻿﻿share information with a wider audience.</li>
</ul>
</li>
</ul>
</li>
<li><p>﻿﻿A retweet is often considered an endorsement, i.e., the user supports the original tweet’s content,</p>
</li>
<li><p>﻿﻿whereas <strong>quoting</strong> may be done in order to express a different idea</p>
</li>
</ul>
<h4 id="Hashtags-amp-mentions"><a href="#Hashtags-amp-mentions" class="headerlink" title="Hashtags&amp;mentions"></a>Hashtags&amp;mentions</h4><ul>
<li>﻿﻿Hashtag - adding a “#” to the beginning of an unbroken word or phrase creates a hashtag.<ul>
<li>When you use a hashtag in a Tweet, it becomes linked to all of the other<br>Tweets that include it.</li>
<li>﻿﻿Including a hashtag gives your Tweet context and allows people to easily follow topics that they’re interested in.</li>
</ul>
</li>
</ul>
<p>@Mentions are used when talking to or about someone (the user account of a person, brand, group, etc.)</p>
<ul>
<li>﻿﻿In marketing</li>
<li>﻿﻿Using hashtags helps a brand connect with what’s happening on Twitter.<br> When brands connect with what’s happening on Twitter, they see</li>
<li>﻿﻿lifts across the marketing funnel, such as<ul>
<li>﻿﻿+18% message association, +8% brand awareness, and +3% purchase intent</li>
</ul>
</li>
</ul>
<h4 id="Twitter-REST-API"><a href="#Twitter-REST-API" class="headerlink" title="Twitter REST API"></a>Twitter REST API</h4><ul>
<li><p>﻿﻿The user Tweet timeline endpoint is a REST endpoint that receives a single path parameter to indicate the desired user (by user ID).</p>
<ul>
<li>﻿﻿The endpoint can return the 3,200 most recent<ul>
<li>﻿﻿Tweets, Retweets, replies, and Quote Tweets posted by the user.</li>
</ul>
</li>
</ul>
</li>
<li><p>﻿﻿User mention timeline</p>
<ul>
<li>﻿﻿The user mention timeline endpoint allows you to request Tweets</li>
<li>﻿﻿mentioning a specific Twitter user, for example,<ul>
<li>﻿﻿if a Twitter account mentioned @TwitterDev within a Tweet</li>
</ul>
</li>
</ul>
</li>
<li><p>it is possible to collect a huge amount of information regarding tweets, accounts, users’ timelines and social networks (i.e., following and followers).</p>
</li>
</ul>
<h4 id="Interaction-among-users"><a href="#Interaction-among-users" class="headerlink" title="Interaction among users"></a>Interaction among users</h4><ul>
<li>﻿﻿In order to understand the connections among users, it is important to consider not only their social networks<ul>
<li>﻿﻿but also, the way they interact, especially through retweets</li>
</ul>
</li>
<li>﻿﻿the Twitter API does not provide complete information about retweets and their propagation paths.<ul>
<li>﻿﻿More precisely, the only information carried by a retweet is the original user</li>
</ul>
</li>
<li>﻿﻿To estimate retweet cascade graphs,<ul>
<li>﻿﻿many strategies based on social network information</li>
<li>﻿﻿(i.e., friends and followers) in conjunction with temporal information</li>
</ul>
</li>
</ul>
<h4 id="Retweet-Graph"><a href="#Retweet-Graph" class="headerlink" title="Retweet Graph"></a>Retweet Graph</h4><ul>
<li><p>﻿﻿a graph of users, where an edge</p>
<ul>
<li>﻿﻿means that one of the users has retweeted a message of a different user.</li>
</ul>
</li>
<li><p>﻿﻿retweet graph G &#x3D; (V, E),</p>
<ul>
<li>﻿﻿which is a graph of users that have participated in the discussion on a specific topic.</li>
<li>﻿﻿A directed edge e &#x3D; (u, v) indicates that user v has retweeted a tweet of u.</li>
<li>﻿﻿Or e &#x3D; (u, v) indicates that user u has retweeted a tweet of v.</li>
</ul>
</li>
</ul>
<p>![image-20230430225752042](..&#x2F;images&#x2F;webs&#x2F;:Users:joshua:Library:Application Support:typora-user-images:image-20230430225752042.png)</p>
<p>Count the number of links to a node in the network</p>
<ul>
<li>﻿﻿the number of directed edges with source (destination)</li>
<li>﻿﻿In-degree - number of retweets of a user<br> Out-degree - number of retweets this particular node (user)<br> made</li>
</ul>
<p>observe the retweet graph at the time instances t &#x3D; 0, 1, 2, . ..,</p>
<ul>
<li>﻿﻿where either a new node or a new edge was added to the graph,</li>
<li>﻿﻿G, &#x3D; (V+, Et) the retweet graph at time t</li>
</ul>
<p><strong>Issues in building interaction graph</strong></p>
<ul>
<li>﻿﻿prior studies exploited the fact that users tend to interact more often with newer tweets,<ul>
<li>﻿﻿and a user is more likely to retweet the last friend who retweeted content.</li>
</ul>
</li>
<li>﻿﻿However, this approach is no longer a reliable way of estimating retweet graphs,</li>
<li>﻿﻿Since, Twitter does not show content based on<ul>
<li>﻿﻿simple reverse chronological order,</li>
<li>﻿﻿but according to user interests, trending topics and interactions</li>
</ul>
</li>
<li>﻿﻿fetch all the required social network information.<ul>
<li>﻿﻿the time required to fetch all</li>
</ul>
</li>
<li>﻿﻿Due to the Twitter API rate limits, the time required to collect the list of friends and followers is<ul>
<li>﻿﻿six times greater with respect to downloading the user’s timeline on average.</li>
</ul>
</li>
</ul>
<p><strong>Some findings</strong></p>
<ul>
<li>﻿﻿analyse the spread mechanics of content through hashtag use</li>
<li>﻿﻿and derive probabilities that users adopt a hashtag.</li>
<li>﻿﻿Hash tags tend to travel to more distant parts of the network and</li>
<li>﻿﻿URLs travel shorter distances.</li>
</ul>
<p>Random graph model</p>
<ul>
<li>﻿﻿Super-star random graph node for a giant component of a retweet graph.</li>
<li>﻿﻿users with many retweets have a higher chance to be retweeted,</li>
<li>﻿﻿however, there is also a super- star node that receives a new retweet at each step with a positive probability.</li>
</ul>
<h3 id="Modellng-Trends"><a href="#Modellng-Trends" class="headerlink" title="Modellng Trends"></a>Modellng Trends</h3><ul>
<li>﻿﻿Trending topics<ul>
<li>﻿﻿Ongoing topics that become suddenly extremely popular</li>
</ul>
</li>
<li>﻿﻿detecting different types of trends, for instance<ul>
<li>﻿﻿detecting emergencies,</li>
<li>﻿﻿earthquakes,</li>
<li>﻿﻿diseases or important events in sports.</li>
</ul>
</li>
<li>﻿﻿An important part of trending behaviour in social media is</li>
<li>﻿﻿the way these trends progress through the network.</li>
</ul>
<h3 id="Two-options"><a href="#Two-options" class="headerlink" title="Two options"></a>Two options</h3><ul>
<li><p>﻿﻿Content of the tweets discussing a topic</p>
<ul>
<li>﻿﻿How do we find this?</li>
</ul>
</li>
<li><p>﻿﻿Underlying networks describing the social ties between users of<br> Twitter</p>
<ul>
<li>﻿﻿a graph of users, where an edge means that one of the users has retweeted a message of a different user.</li>
</ul>
</li>
<li><p>﻿﻿In both cases, we could ask</p>
<ul>
<li><p>﻿﻿How big or small interaction network compared to followers’ network?</p>
</li>
<li><p>What kind of information goes through the network?</p>
<ul>
<li>85% of content is&#x2F;was News!</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="Largest-connected-component-LCC"><a href="#Largest-connected-component-LCC" class="headerlink" title="Largest connected component LCC"></a>Largest connected component LCC</h4><ul>
<li>LCC refers to a maximum set of nodes</li>
<li>such that you can move from any node to any other node</li>
<li>in this set by only moving between side-adjacent nodes from the graph.</li>
</ul>
<p>All components of a graph can be found by looping through its vertices,</p>
<p>starting a new breadth-first or depth-first search whenever the loop reaches a vertex that has not already been included in a previously found component.</p>
<p><strong>Graph density</strong></p>
<ul>
<li>﻿﻿represents the ratio between the edges present in a graph ﻿﻿and the maximum number of edges that the graph can contain.</li>
<li>﻿﻿Conceptually, it provides an idea of how dense a graph is in terms of edge connectivity.</li>
<li>﻿﻿In this work |E|&#x2F;|V|</li>
</ul>
<p><strong>size</strong> of the largest connected component (LCC) and its <strong>density</strong> are the most informative characteristics for predicting the peak in Twitter. </p>
<h4 id="Information-diffusion-amp-influencers"><a href="#Information-diffusion-amp-influencers" class="headerlink" title="Information diffusion &amp; influencers"></a>Information diffusion &amp; influencers</h4><p>Issue with retweet graph</p>
<ul>
<li><p>﻿﻿users might be exposed and influenced by a piece of information by multiple users, hence forming multiple influence paths</p>
</li>
<li><p>﻿﻿When a message arrives that is a retweet, every friend that has (re)tweeted at an earlier point in time ﻿﻿has to be considered as a potential influencer</p>
</li>
<li><p>﻿﻿there is no agreement on the minimum number of followers needed to be regarded as an “influencer”</p>
</li>
<li><p>﻿﻿In fact, in marketing, they talk about</p>
<ul>
<li>Micro-influencers</li>
</ul>
</li>
</ul>
<p><strong>Influence paths express the relationship of “who was influenced by whom”.</strong> </p>
<p>The set of influence paths form a social graph, that share a <strong>common root</strong> (a single user who first seeded a tweet). Influence path is referred as “information cascade”. A cascade is formed when users forward the same original message from a user that we call the root user.</p>
<p><strong>Information cascade model</strong></p>
<ul>
<li><p>﻿how information is being propagated from user to user from the stream of messages and the social graph.</p>
</li>
<li><p>﻿Nodes of the cascade represent users (user nodes) of the social network that got ﻿“influenced” by the root or another user.</p>
</li>
<li><p>﻿Edges of the cascade represent edges of the social graph over which influence actually spread.</p>
</li>
</ul>
<p><strong>An “influencer” in the case of Twitter is the so called “friend” that exposes information to his&#x2F;her followers and</strong></p>
<p>exerts influence on them in such a way that they forward this piece of information.</p>
<p>However, real data is missing?</p>
<p>we can derive these influence paths from these social connections among users.</p>
<p><strong>Absolute Interaction strength</strong></p>
<p>![image-20230501103443357](..&#x2F;images&#x2F;webs&#x2F;:Users:joshua:Library:Application Support:typora-user-images:image-20230501103443357.png)</p>
<p><strong>Retweet distribution</strong> </p>
<ul>
<li>﻿﻿The retweet distribution given the time delay between the retweet action date and the original tweet posting time<ul>
<li>﻿﻿for 16,304 cascades</li>
</ul>
</li>
<li>Temporal dynamics of the retweets after the respective roottime</li>
<li>﻿﻿Showing a decreasing trend,<ul>
<li>﻿﻿as the highest number of interactions occurred</li>
<li>﻿﻿soon after roottime (the original tweet creation date).</li>
</ul>
</li>
</ul>
<p><strong>Weighted information strength</strong></p>
<p>![image-20230501103700956](..&#x2F;images&#x2F;webs&#x2F;:Users:joshua:Library:Application Support:typora-user-images:image-20230501103700956.png)</p>
<p>![image-20230501103748922](..&#x2F;images&#x2F;webs&#x2F;:Users:joshua:Library:Application Support:typora-user-images:image-20230501103748922.png)</p>
<p><strong>Approach - Generating Retweet Cascade Graphs</strong> </p>
<p>![image-20230501103852547](..&#x2F;images&#x2F;webs&#x2F;:Users:joshua:Library:Application Support:typora-user-images:image-20230501103852547.png)</p>
<p><strong>No interaction</strong></p>
<p>![image-20230501103945037](..&#x2F;images&#x2F;webs&#x2F;:Users:joshua:Library:Application Support:typora-user-images:image-20230501103945037.png)</p>
<p><strong>In addition</strong></p>
<ul>
<li>﻿﻿when there are no available interactions by a user u, and thus</li>
<li>﻿﻿no IS values between u and any other user,</li>
<li>﻿﻿An alternative is to find a link from the u to another user in the cascade</li>
<li>﻿﻿collect the user’s friend list by using the Twitter API, and</li>
<li>﻿﻿every user’s friend that has retweeted at an earlier point in time is considered as a potential influencer</li>
<li>﻿﻿To identify the influencer that more likely spread the tweet to user u,</li>
<li>﻿﻿consider the most recent influencer, i.e., u is linked to the last friend that retweeted the message.</li>
<li>﻿﻿Users that still remaining without an edge after this second step are denoted as sparse nodes<br> (SN).</li>
</ul>
<p><strong>How do you find influencer nodes and communities?</strong></p>
<ul>
<li>How could we find important nodes?<ul>
<li>Influencers?</li>
</ul>
</li>
<li>How can we find the information paths?<ul>
<li>What measures you may use? <strong>Centrality</strong>, <strong>Degrees</strong>.</li>
</ul>
</li>
<li>What alternative mechanisms to weight graphs?</li>
</ul>
<h3 id="L8-Network-Analysis-Case-studies-in-Health-Communities"><a href="#L8-Network-Analysis-Case-studies-in-Health-Communities" class="headerlink" title="L8 Network Analysis - Case studies in Health Communities"></a>L8 Network Analysis - Case studies in Health Communities</h3><h4 id="Case-studies"><a href="#Case-studies" class="headerlink" title="Case studies"></a>Case studies</h4><p>How online communities of people with long-term conditions function &amp; evolve: network analysis of the structure and dynamics of the asthma UK and British lung foundation online communities,</p>
<p><strong>Problems</strong></p>
<ul>
<li><p>﻿﻿We have seen</p>
<ul>
<li><p>﻿﻿People express themselves through social media</p>
</li>
<li><p>﻿﻿Huge amount of data</p>
</li>
</ul>
</li>
<li><p>﻿﻿People suffering from mental health</p>
<ul>
<li>﻿﻿Silent suffering!</li>
</ul>
</li>
<li><p>﻿﻿Can we create a self-management or self-diagnosis tool</p>
<ul>
<li><p>﻿﻿A tool helping them to control their situation</p>
</li>
<li><p>﻿﻿A tool nudging them to get help!!</p>
</li>
</ul>
</li>
<li><p>﻿﻿To start with</p>
<ul>
<li>﻿﻿How prevalent is mental health issues in society?</li>
</ul>
</li>
<li><p>﻿﻿Can we mine network structure of social media to understand how communities support mental health issues?</p>
<ul>
<li>﻿﻿Network structure of social media data provide insights on support given by society on mental health issues</li>
</ul>
</li>
</ul>
<p><strong>Social Support</strong></p>
<p>Social Support is an exchange of resources between two individuals</p>
<ul>
<li><p>﻿﻿perceived by the provider or the recipient to be intended</p>
</li>
<li><p>﻿﻿to enhance the well-being of the recipient</p>
<ul>
<li><p>﻿﻿e.g.,</p>
<ul>
<li><p>﻿﻿Facebook interaction</p>
</li>
<li><p>﻿﻿RTs …</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>How to extract signatures of perceived social support?</p>
<p><strong>Post-reply Network</strong></p>
<p>Example -&gt; StackOverflow</p>
<p>It is not like twitter, its form is due to the users shared same interest.</p>
<p>A community expertise network.</p>
<h4 id="Graph-modelling-WHAT-IS-INTERACTION-GRAPH"><a href="#Graph-modelling-WHAT-IS-INTERACTION-GRAPH" class="headerlink" title="Graph modelling WHAT IS INTERACTION GRAPH"></a><strong>Graph modelling WHAT IS INTERACTION GRAPH</strong></h4><p><strong>User interaction graph</strong></p>
<p>Tie</p>
<ul>
<li><p>﻿﻿Tie connect a pair of users&#x2F;actors by one or more relations</p>
<ul>
<li><p>﻿﻿Sharing information, financial or Psychological support</p>
</li>
<li><p>﻿﻿One relation or multiple set of relations</p>
</li>
<li><p>﻿﻿Vary in content, direction &amp; strength</p>
</li>
</ul>
</li>
<li><p>﻿﻿look at the actual tie between users instead of message level interactions</p>
</li>
</ul>
<p><strong>Structural prestige in online communities</strong></p>
<ul>
<li><p>﻿﻿A thread</p>
<ul>
<li>How many people a user replied (out degree!!)</li>
<li>﻿﻿How many people replied to the user (in degree!!)</li>
</ul>
</li>
<li><p>﻿﻿In directed networks</p>
<ul>
<li><p>﻿﻿People who send many responses&#x2F;replies</p>
</li>
<li><p>﻿﻿are considered to be prestigious</p>
</li>
<li><p>﻿﻿Or person with knowledge</p>
</li>
</ul>
</li>
</ul>
<p><strong>Size of a node</strong></p>
<ul>
<li>﻿﻿the size of the node depends on the number of replies send by the user</li>
<li>﻿﻿The more the number of replies, the larger the node</li>
</ul>
<p><strong>How to create an interaction graph?</strong></p>
<ul>
<li><p>﻿﻿the users who post and the corresponding reply users</p>
</li>
<li><p>﻿﻿A Pandas DataFrame contains two columns of node names</p>
<ul>
<li>﻿﻿posts_author, comments_author.</li>
</ul>
</li>
<li><p>﻿﻿use nx.from pandas_ edgelist() to transfer the DataFrame to a network graph.</p>
<ul>
<li><p>﻿﻿Network (NX) is a python software package,</p>
</li>
<li><p>﻿﻿used to create and operate complex networks,</p>
</li>
<li><p>﻿﻿and to learn the structure, dynamics and functions of complex networks.</p>
</li>
</ul>
</li>
<li><p>﻿﻿To distinguish the importance of each user who post,</p>
<ul>
<li><p>﻿﻿we set the size of these users’ to twice its node degree<br> User’s node orange</p>
</li>
<li><p>﻿﻿Replies node to light gray the directed edges to light blue colour.</p>
</li>
</ul>
</li>
</ul>
<p><strong>Temporal activity patterns</strong></p>
<ul>
<li>Let us study how the community thrive?<ul>
<li>How do they function and evolve over time?</li>
</ul>
</li>
<li>Basically we are answering research questions <ul>
<li>like “ what is the basic structure of SUCH online communities and how do they function and evolve over time”</li>
</ul>
</li>
</ul>
<p><strong>Degree distributions</strong></p>
<ul>
<li><p>﻿﻿Look at the distribution of degrees,</p>
</li>
<li><p>﻿﻿Or the amount of edges a node has</p>
</li>
<li><p>﻿﻿Acros sall nodes in a graph</p>
</li>
<li><p>﻿﻿Top 1% of nodes</p>
<ul>
<li><p>﻿﻿in terms of degrees</p>
</li>
<li><p>﻿﻿most interactive and have<br> Established edges with a lot of other users by exchanging messages</p>
</li>
<li><p>﻿﻿Known as super users,</p>
</li>
</ul>
</li>
</ul>
<p><strong>Activity analysis</strong></p>
<ul>
<li><p>﻿﻿How are users engaging or community thrive?</p>
<ul>
<li>﻿﻿Does posting activity follow a time pattern?</li>
</ul>
</li>
<li><p>﻿﻿How many activity is happening on a daily or weekly basis on a particular community</p>
<ul>
<li><p>﻿﻿Number of messages exchanged in a community across the whole life cycle of data</p>
</li>
<li><p>﻿﻿how users engaging with a community</p>
</li>
</ul>
</li>
<li><p>﻿﻿Cumulative frequencies of activity</p>
<ul>
<li>﻿﻿Number of posts reply per week</li>
</ul>
</li>
</ul>
<p><strong>To understand the behaviour of the community</strong></p>
<ul>
<li><p>the trend tends to be linear,</p>
<ul>
<li>which indicates that the number of new replies per week remains stable.</li>
</ul>
</li>
<li><p>SuicideWatch, average 211605 posts to come weekly and PSTD average 1980 posts</p>
</li>
<li><p>This shows that the average weekly posting volume of Suicide Watch community users is almost 100 times that of PTSD.</p>
<ul>
<li>227,307 users in the SuicideWatch community, while PTSD has only 50032 users,</li>
</ul>
</li>
</ul>
<p><strong>Open question – how do we distinguish two communities?</strong></p>
<p>Modularity Optimization: Modularity is a measure of the degree to which nodes in a network are connected within their own community compared to the connections between different communities. Modularity optimization involves identifying communities that maximize modularity, or in other words, communities that have a high degree of internal connections and a low degree of external connections.</p>
<p>Girvan-Newman Algorithm: This algorithm involves iteratively removing edges from the network in order of their “betweenness centrality,” which is a measure of how often a given edge lies on the shortest path between two nodes. By removing edges in this way, the algorithm gradually breaks the network into smaller and smaller communities.</p>
<p>Label Propagation: This method involves assigning an initial label to each node in the network and then iteratively updating the labels based on the labels of neighboring nodes. Over time, nodes tend to cluster into groups with similar labels, forming communities.</p>
<p>Spectral Clustering: This method involves using the eigenvalues and eigenvectors of the network’s adjacency matrix to identify communities. By projecting the network onto a lower-dimensional space, spectral clustering can often separate nodes into distinct communities.</p>
<p> <strong>how did we study the behaviour of two communities &amp; what did we found?</strong></p>
<ul>
<li><p>﻿﻿For each week</p>
</li>
<li><p>﻿﻿Compute average post</p>
<ul>
<li><p>﻿﻿Look at the total posts by all users</p>
</li>
<li><p>﻿﻿Divided by total number of unique users</p>
</li>
</ul>
</li>
<li><p>﻿﻿How users are engaging with the community?</p>
<ul>
<li><p>﻿﻿A continuous engagement is good for the vitality of community.</p>
</li>
<li><p>﻿﻿Do these communities drive enough engagement and activity to sustain</p>
</li>
</ul>
</li>
</ul>
<p><strong>Super users</strong></p>
<ul>
<li><p>﻿﻿A small minority of users</p>
<ul>
<li><p>﻿﻿Responsible for a high proportion of posting activity and thus support</p>
</li>
<li><p>﻿﻿Functioning of communities</p>
</li>
</ul>
</li>
<li><p>﻿﻿5% of users generate</p>
<ul>
<li>﻿﻿Over 70% of content</li>
</ul>
</li>
<li><p>﻿How do we study the role of super users?</p>
<ul>
<li>﻿﻿Sensitivity analysis</li>
</ul>
</li>
</ul>
<p><strong>How to find the super user?</strong></p>
<ul>
<li><p>﻿﻿For each user</p>
<ul>
<li><p>﻿﻿Count the number of posts (A) and</p>
</li>
<li><p>﻿﻿The number of replies (B)</p>
</li>
<li><p>﻿﻿The number of total activity (A + B)</p>
</li>
</ul>
</li>
<li><p>﻿﻿Rank the user in terms of respective frequencies</p>
</li>
</ul>
<p><strong>Connected component</strong></p>
<ul>
<li>﻿﻿A connected component of an undirected graph is a maximal set of nodes such that<ul>
<li>﻿﻿each pair of nodes is connected by a path.</li>
</ul>
</li>
<li>﻿﻿Directed graphs have weakly and strongly connected components.</li>
<li>﻿﻿Two vertices are in the same weakly connected<br> component<ul>
<li>﻿﻿if they are connected by a path, where paths are allowed to go either way along any edge.</li>
</ul>
</li>
<li>﻿﻿The weakly connected components correspond closely to the concept of connected component in undirected graphs and the typical situation is similar<ul>
<li>﻿﻿there is usually one large weakly connected component plus other small ones.</li>
</ul>
</li>
</ul>
<p><strong>Largest connected component</strong></p>
<ul>
<li><p>﻿﻿A largest connected component of a</p>
<ul>
<li><p>﻿﻿Graph G(V,E) is the largest possible subgraph</p>
<ul>
<li><p>﻿G_L(V_L,E_L) of G,</p>
</li>
<li><p>﻿﻿such that each node in G_L, has at least one valid connected path to every other node in G_L,</p>
</li>
</ul>
</li>
</ul>
</li>
<li><p>﻿﻿LCC gives us the subset of users</p>
<ul>
<li>﻿﻿Who form a cohesive community</li>
</ul>
</li>
<li><p>﻿﻿Importance of super users on LCC</p>
<ul>
<li>﻿﻿By removing them and studying the cohesion</li>
</ul>
</li>
</ul>
<p><strong>Community resilience</strong></p>
<p>Temporal Analysis</p>
<ul>
<li><p>﻿﻿Characteristics of LCC on a weekly basis</p>
</li>
<li><p>﻿﻿Focused and cohesive nature of interactions</p>
<ul>
<li>﻿﻿By looking at the fraction of users belonging to the LCC.</li>
</ul>
</li>
<li><p>﻿﻿Our aim is to study</p>
<ul>
<li>﻿﻿community resilience</li>
</ul>
</li>
<li><p>﻿﻿First how cohesive</p>
<ul>
<li>﻿﻿The community is?</li>
</ul>
</li>
<li><p>﻿﻿For each weekly graph, G</p>
<ul>
<li><p>﻿﻿Compute the LCC</p>
</li>
<li><p>﻿﻿That is all nodes in LCC has at least one path</p>
</li>
</ul>
</li>
<li><p>﻿﻿Compute fraction N&#x2F;N</p>
<ul>
<li>﻿﻿Nk is the nodes in LCC</li>
</ul>
</li>
</ul>
<p><strong>Fragility of the community</strong></p>
<ul>
<li><p>﻿﻿If the conversation network is held by</p>
<ul>
<li><p>﻿﻿A more or less uniform contribution of nodes</p>
</li>
<li><p>﻿﻿Or</p>
</li>
<li><p>﻿﻿Is there a skew in the responsibility of nodes</p>
</li>
</ul>
</li>
<li><p>﻿﻿Sensitivity analysis methods</p>
<ul>
<li>﻿﻿Which measures the network’s capacity to diffuse information as you move nodes based on certain property</li>
</ul>
</li>
<li><p>﻿﻿Importance of super users</p>
</li>
</ul>
<p><strong>Sensitivity analysis</strong></p>
<ul>
<li>﻿﻿the targeted removal of nodes (users) starting from the most connected nodes.</li>
<li>﻿﻿represents the size of the largest component as a percentage of the network size.</li>
<li>﻿﻿Specifically, it illustrates the key effects of the superusers on the website from another perspective.</li>
</ul>
<p><strong>Rich club effect</strong></p>
<ul>
<li><p>﻿﻿that a few important nodes (users) show stronger and closer connection with each other,</p>
<ul>
<li>﻿﻿and constitute a structural core and functional hub.</li>
</ul>
</li>
<li><p>﻿﻿the rich-club coefficient</p>
<ul>
<li>is the ratio of the actual number of edges of nodes with order greater than k</li>
<li>﻿﻿to the number of potential edges of each order k</li>
</ul>
</li>
</ul>
<p>![image-20230501161132105](..&#x2F;images&#x2F;webs&#x2F;:Users:joshua:Library:Application Support:typora-user-images:image-20230501161132105.png)</p>
<ul>
<li>the coefficient continues to be lower than 1,<ul>
<li>indicating that the amount of interaction between superusers are not high, </li>
<li>the amount of interactions between most non-superusers are also not high.</li>
</ul>
</li>
<li>the interactions between the superusers and non-superusers are very high,<ul>
<li>indicating that superusers are more inclined to communicate with users with fewer interactive connections.</li>
</ul>
</li>
<li>How do we explain this<ul>
<li>there are a large number of users with purposeful questions on the website and a small number of experts in the field.</li>
</ul>
</li>
</ul>
<h4 id="Z-score"><a href="#Z-score" class="headerlink" title="Z-score"></a>Z-score</h4><ul>
<li><p>﻿﻿We have seen core users and their relationship with other users from the graph</p>
</li>
<li><p>﻿﻿We do not know whether core users</p>
<ul>
<li><p>﻿﻿Tend to ask for help (post more)</p>
</li>
<li><p>﻿﻿Help others (reply more</p>
</li>
</ul>
</li>
<li><p>﻿﻿Look at a thread!</p>
</li>
<li><p>﻿﻿To find that out let us look at z-score!!<br>z &#x3D; (х - mean)&#x2F;sd</p>
</li>
</ul>
<h4 id><a href="#" class="headerlink" title></a></h4><h2 id="Emotion-Analysis"><a href="#Emotion-Analysis" class="headerlink" title="Emotion Analysis"></a>Emotion Analysis</h2><h3 id="L9"><a href="#L9" class="headerlink" title="L9"></a>L9</h3><h4 id="Sentiment-analysis-amp-variants"><a href="#Sentiment-analysis-amp-variants" class="headerlink" title="Sentiment analysis &amp; variants"></a>Sentiment analysis &amp; variants</h4><p><strong>Variants</strong></p>
<ul>
<li>﻿﻿<strong>Sentiment classification</strong><ul>
<li>﻿﻿whether a piece of text is positive, negative or neutral</li>
<li>﻿﻿Degree of intensity<ul>
<li>﻿﻿[-100,100]</li>
</ul>
</li>
</ul>
</li>
<li>﻿﻿Opinion analysis<ul>
<li>Determining from text, the speaker’s opinion and target of the opinion</li>
</ul>
</li>
<li>﻿﻿Stance<ul>
<li>﻿﻿Author of text is in favour of, against of, or neutral towards a proposition or target</li>
<li>﻿﻿For example, Brexit agreement<ul>
<li>﻿﻿Is people supportive?</li>
</ul>
</li>
</ul>
</li>
<li>﻿﻿<strong>Emotion</strong><ul>
<li>﻿﻿What are the emotion expressed in the text?</li>
</ul>
</li>
</ul>
<p><strong>Sentiment vs Stance</strong></p>
<ul>
<li>﻿﻿Target:<ul>
<li>﻿﻿Legalization of Abortion</li>
</ul>
</li>
<li>﻿﻿Tweet<ul>
<li>The pregnant are more than walking incubators. They have rights too!</li>
<li>﻿﻿In favour of the target</li>
<li>﻿﻿Target - Pro-life movement<ul>
<li>﻿??</li>
</ul>
</li>
</ul>
</li>
<li>﻿﻿Target<ul>
<li>﻿﻿Donald Trump</li>
</ul>
</li>
<li>﻿﻿Tweet<ul>
<li>﻿﻿Donald Trump has some strengths and some weakness<ul>
<li>neutral</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>Stance detection</strong></p>
<ul>
<li>﻿﻿Is the task of automatically determining from text<ul>
<li>﻿﻿whether the author of the text is in favour of, against of, or neutral</li>
<li>﻿﻿toward a proposition or target</li>
</ul>
</li>
<li>﻿﻿Target<ul>
<li>﻿﻿Person, organization, government policy, a movement, a product</li>
<li>﻿﻿E.g., infer from former Prime minister Boris Jonson’s speeches that he is in favour of Brexit</li>
<li>﻿﻿E.g., analysing tweets identify people in favour of leadership change</li>
</ul>
</li>
</ul>
<p>Aspect Based Sentiment Analysis</p>
<ul>
<li>﻿﻿A sentence contains one or more entities,<ul>
<li>﻿﻿each of which has a different polarity of emotion.</li>
</ul>
</li>
<li>﻿﻿For example, give a comment like<ul>
<li>﻿﻿“Great food but the service is dreadful!”,</li>
<li>﻿﻿the emotional polarity of entity “food” is “positive”</li>
<li>﻿﻿while the emotional polarity of entity “service” is “negative”.</li>
</ul>
</li>
<li>﻿﻿Compared to sentence level sentiment analysis, ABSA can present<ul>
<li>﻿﻿users with more precise and fine-grained sentiment information of entities</li>
</ul>
</li>
<li>﻿﻿You identify an aspect and the sentiment towards that aspect</li>
</ul>
<p><strong>Sentiment classifification is limited</strong></p>
<ul>
<li>﻿﻿Language serves social and interpersonal functions.<ul>
<li>﻿﻿Affective meaning is key for human interaction and a prominent characteristic of language use.</li>
</ul>
</li>
<li>﻿﻿This extends beyond<ul>
<li>﻿﻿opinions vs. factual or polarity distinctions</li>
<li>﻿﻿into multiple phenomena:<ul>
<li>﻿﻿emotion, mood, personality, attitude, credibility, volition, veracity, friendliness, etc.</li>
</ul>
</li>
</ul>
</li>
<li>﻿﻿<strong>Emotion:</strong><ul>
<li>﻿﻿angry, sad, joyful, fearful, …</li>
</ul>
</li>
<li>﻿﻿recognition, characterization, or generation of affect states,<ul>
<li>﻿﻿involves analysis of affect-related conditions, experiences, and activities.</li>
</ul>
</li>
</ul>
<p><strong>Textual emotion</strong></p>
<ul>
<li>﻿﻿We analyse the text and detect the emotion<ul>
<li>﻿﻿expressed by the author or</li>
<li>﻿﻿the emotion potentially felt by the reader</li>
</ul>
</li>
<li>﻿﻿Linguistic sensing of affective states can be used for<ul>
<li>﻿﻿Understanding social issues expressed through social media</li>
</ul>
</li>
<li>﻿﻿Researchers in psychological science believe that<ul>
<li>﻿﻿individuals have internal mechanisms for a limited collection of responses, usually</li>
<li>﻿﻿happy, sad, anger, disgust, and fear</li>
</ul>
</li>
</ul>
<p><strong>There are 6 emoMon categories that are widely used to describe</strong> </p>
<p>humans’ basic emoMons, based on facial expression: </p>
<p><strong>anger, disgust, fear,</strong> <strong>happiness</strong>, <strong>sadness</strong> and <strong>surprise</strong>.</p>
<ul>
<li>Categorical theories</li>
<li>EmoIons are discretely and difffferently constructed and</li>
<li>all humans are thought to have an innate set of basic emoIon </li>
<li>that are cross-culturally recognisable</li>
</ul>
<p><strong>OCC model</strong></p>
<p>22 emotions &#x3D; 6 Paul Ekman emotions + 16 addtional emotions</p>
<p><strong>Criticism</strong></p>
<ul>
<li>In the categorical approach, emotional states are restricted to a limited number of distinct types and</li>
<li>it can be difficult to resolve a complex emotional situation or mixed emotions.</li>
<li>Appraisal theory</li>
<li>It contains componential emotion models based on the theory of appraisal.</li>
<li>Appraisal theory describes how different emotions, in various participants and on different times, can arise from the same event</li>
</ul>
<h4 id="Text-emotion-detection"><a href="#Text-emotion-detection" class="headerlink" title="Text emotion detection"></a>Text emotion detection</h4><p><strong>motivation</strong></p>
<ul>
<li>﻿﻿because of the naturally vague and ambiguous human language is,<ul>
<li>﻿﻿the emotion detection can be highly “context-sensitive and complex”</li>
</ul>
</li>
<li>﻿﻿Emotion analysis is a convoluted task, even for human beings,<ul>
<li>﻿﻿due to the various cultures, gender, and context of people who authored the texts.</li>
<li>﻿﻿The task will be much easier when emotion is expressed explicitly, but in reality,</li>
<li>﻿﻿the majority of texts are subtle, ambiguous, and some words have more than one meaning, and</li>
<li>﻿﻿more than one word expresses the same emotions, and, in addition, some emotions can exist simultaneously</li>
</ul>
</li>
<li>﻿﻿Don’t u just HATE it when u cannot find something that u know you just saw like<br> 10 min ago!</li>
<li>By analysing the horse racing comments,</li>
<li>﻿﻿the model can learn about the information of winning horse and</li>
<li>﻿﻿would be able to give a reasonable prediction based on the emotion.</li>
</ul>
<p><strong>emotion classification</strong></p>
<ul>
<li>﻿﻿In the case of sentiment analysis, this task can be tackled using<ul>
<li>﻿﻿lexicon-based methods, machine learning, or a reule-based approach</li>
</ul>
</li>
<li>﻿﻿In emotion recognition task, the 4 most common approaches are<ul>
<li>﻿﻿Keyword-based detection<ul>
<li>﻿﻿Seed opinion words and find synonyms &amp; antonyms in WordNet</li>
<li>﻿﻿WordNet</li>
</ul>
</li>
</ul>
</li>
<li>﻿﻿Lexical affinity</li>
<li>﻿﻿hybrid</li>
<li>﻿﻿Learning based detection</li>
</ul>
<p><strong>Lexicon</strong></p>
<ul>
<li>﻿﻿Lexicons are linguistic tools for automated analysis of text</li>
<li>﻿﻿Most common<ul>
<li>﻿﻿Simple list of terms associated to a certain class of interest</li>
<li>﻿﻿Classification by counting</li>
<li>﻿﻿Terms can be weighted according to their strength of association with a given class</li>
</ul>
</li>
</ul>
<p>Lexicon based approaches?</p>
<ul>
<li>﻿﻿“I love horror books”</li>
<li>﻿﻿f(love) × 1.0 + f(horror) x 0.3 + f(books) x 0.5 &#x3D; 1.8 for positive</li>
<li>﻿﻿f(love) x 0.0 + f(horror) x 0.7 + f(books) × 0.5 &#x3D; 1.2 for negative</li>
<li>﻿﻿Decision function<ul>
<li>﻿﻿Classify one with maximum value</li>
</ul>
</li>
<li>Transparency<ul>
<li>﻿﻿Each prediction can be explained<ul>
<li>﻿﻿Analysing terms that were present in the text</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>BERT VS gpt</strong></p>
<h1 id="Mock-Paper"><a href="#Mock-Paper" class="headerlink" title="Mock Paper"></a>Mock Paper</h1><h2 id="2022"><a href="#2022" class="headerlink" title="2022"></a>2022</h2><ol>
<li></li>
</ol>
<p>(a) Assume that the BBC recruited you to develop a social media application. The BBC is interested in knowing their readers’ feelings on the news and other events covered by the broadcaster. Your job is to develop a classifier. In this context, answer the following questions:</p>
<p>(i)</p>
<p>Your first task is to create Twitter datasets with positive and negative statements so that they can be used for estimating the probabilities for words in the respective classes. [Hint: Assuming that you have a social media crawler, discuss how you will automatically label positive and negative tweets; how will you avoid spurious data]</p>
<p>(ii)</p>
<p>Your second task is to develop a lexicon-based automatic sentiment analysis method, which assigns sentiment intensity between [-100,100].Describe an algorithm that also uses the dataset you created in (i). [Hint: identify a suitable lexicon; identify linguistic cases you may handle; specify a scoring method] </p>
<p>(iii)</p>
<p>Now that you created a sentiment analysis method, you want to verify the method’s validity from a user’s perspective. Design a scalable user-based study to ensure your sentiment scoring method is appropriate.</p>
 
      <!-- reward -->
      
      <div id="reword-out">
        <div id="reward-btn">
          Donate
        </div>
      </div>
      
    </div>
    

    <!-- copyright -->
    
    <div class="declare">
      <ul class="post-copyright">
        <li>
          <i class="ri-copyright-line"></i>
          <strong>Copyright： </strong>
          
          Copyright is owned by the author. For commercial reprints, please contact the author for authorization. For non-commercial reprints, please indicate the source.
          
        </li>
      </ul>
    </div>
    
    <footer class="article-footer">
       
<div class="share-btn">
      <span class="share-sns share-outer">
        <i class="ri-share-forward-line"></i>
        Share
      </span>
      <div class="share-wrap">
        <i class="arrow"></i>
        <div class="share-icons">
          
          <a class="weibo share-sns" href="javascript:;" data-type="weibo">
            <i class="ri-weibo-fill"></i>
          </a>
          <a class="weixin share-sns wxFab" href="javascript:;" data-type="weixin">
            <i class="ri-wechat-fill"></i>
          </a>
          <a class="qq share-sns" href="javascript:;" data-type="qq">
            <i class="ri-qq-fill"></i>
          </a>
          <a class="douban share-sns" href="javascript:;" data-type="douban">
            <i class="ri-douban-line"></i>
          </a>
          <!-- <a class="qzone share-sns" href="javascript:;" data-type="qzone">
            <i class="icon icon-qzone"></i>
          </a> -->
          
          <a class="facebook share-sns" href="javascript:;" data-type="facebook">
            <i class="ri-facebook-circle-fill"></i>
          </a>
          <a class="twitter share-sns" href="javascript:;" data-type="twitter">
            <i class="ri-twitter-fill"></i>
          </a>
          <a class="google share-sns" href="javascript:;" data-type="google">
            <i class="ri-google-fill"></i>
          </a>
        </div>
      </div>
</div>

<div class="wx-share-modal">
    <a class="modal-close" href="javascript:;"><i class="ri-close-circle-line"></i></a>
    <p>扫一扫，分享到微信</p>
    <div class="wx-qrcode">
      <img src="//api.qrserver.com/v1/create-qr-code/?size=150x150&data=http://example.com/2023/04/28/webscience/" alt="微信分享二维码">
    </div>
</div>

<div id="share-mask"></div>  
    </footer>
  </div>

   
  <nav class="article-nav">
    
    
      <a href="/2023/04/25/DSA/" class="article-nav-link">
        <strong class="article-nav-caption">Next Post</strong>
        <div class="article-nav-title">DSA</div>
      </a>
    
  </nav>

  
   
    
    <script src="https://cdn.staticfile.org/twikoo/1.4.18/twikoo.all.min.js"></script>
    <div id="twikoo" class="twikoo"></div>
    <script>
        twikoo.init({
            envId: ""
        })
    </script>
 
</article>

</section>
      <footer class="footer">
  <div class="outer">
    <ul>
      <li>
        Copyrights &copy;
        2021-2023
        <i class="ri-heart-fill heart_icon"></i> Mingwei Li
      </li>
    </ul>
    <ul>
      <li>
        
      </li>
    </ul>
    <ul>
      <li>
        
        
        <span>
  <span><i class="ri-user-3-fill"></i>Visitors:<span id="busuanzi_value_site_uv"></span></span>
  <span class="division">|</span>
  <span><i class="ri-eye-fill"></i>Views:<span id="busuanzi_value_page_pv"></span></span>
</span>
        
      </li>
    </ul>
    <ul>
      
    </ul>
    <ul>
      
    </ul>
    <ul>
      <li>
        <!-- cnzz统计 -->
        
        <script type="text/javascript" src='https://s9.cnzz.com/z_stat.php?id=1278069914&amp;web_id=1278069914'></script>
        
      </li>
    </ul>
  </div>
</footer>    
    </main>
    <div class="float_btns">
      <div class="totop" id="totop">
  <i class="ri-arrow-up-line"></i>
</div>

<div class="todark" id="todark">
  <i class="ri-moon-line"></i>
</div>

    </div>
    <aside class="sidebar on">
      <button class="navbar-toggle"></button>
<nav class="navbar">
  
  <div class="logo">
    <a href="/"><img src="/images/ayer-side.svg" alt="Mingwei’s Blog"></a>
  </div>
  
  <ul class="nav nav-main">
    
    <li class="nav-item">
      <a class="nav-item-link" href="/">Home</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/archives">Archives</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/categories">Categories</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags">Tags</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" target="_blank" rel="noopener" href="http://shenyu-vip.lofter.com">Gallery</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags/%E6%97%85%E8%A1%8C/">Travel</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/2019/about">About</a>
    </li>
    
  </ul>
</nav>
<nav class="navbar navbar-bottom">
  <ul class="nav">
    <li class="nav-item">
      
      <a class="nav-item-link nav-item-search"  title="Search">
        <i class="ri-search-line"></i>
      </a>
      
      
      <a class="nav-item-link" target="_blank" href="/atom.xml" title="RSS Feed">
        <i class="ri-rss-line"></i>
      </a>
      
    </li>
  </ul>
</nav>
<div class="search-form-wrap">
  <div class="local-search local-search-plugin">
  <input type="search" id="local-search-input" class="local-search-input" placeholder="Search...">
  <div id="local-search-result" class="local-search-result"></div>
</div>
</div>
    </aside>
    <div id="mask"></div>

<!-- #reward -->
<div id="reward">
  <span class="close"><i class="ri-close-line"></i></span>
  <p class="reward-p"><i class="ri-cup-line"></i>请我喝杯咖啡吧~</p>
  <div class="reward-box">
    
    <div class="reward-item">
      <img class="reward-img" src="/images/alipay.jpg">
      <span class="reward-type">支付宝</span>
    </div>
    
    
    <div class="reward-item">
      <img class="reward-img" src="/images/wechat.jpg">
      <span class="reward-type">微信</span>
    </div>
    
  </div>
</div>
    
<script src="/js/jquery-3.6.0.min.js"></script>
 
<script src="/js/lazyload.min.js"></script>

<!-- Tocbot -->
 
<script src="/js/tocbot.min.js"></script>

<script>
  tocbot.init({
    tocSelector: ".tocbot",
    contentSelector: ".article-entry",
    headingSelector: "h1, h2, h3, h4, h5, h6",
    hasInnerContainers: true,
    scrollSmooth: true,
    scrollContainer: "main",
    positionFixedSelector: ".tocbot",
    positionFixedClass: "is-position-fixed",
    fixedSidebarOffset: "auto",
  });
</script>

<script src="https://cdn.staticfile.org/jquery-modal/0.9.2/jquery.modal.min.js"></script>
<link
  rel="stylesheet"
  href="https://cdn.staticfile.org/jquery-modal/0.9.2/jquery.modal.min.css"
/>
<script src="https://cdn.staticfile.org/justifiedGallery/3.8.1/js/jquery.justifiedGallery.min.js"></script>

<script src="/dist/main.js"></script>

<!-- ImageViewer -->
 <!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>

<link rel="stylesheet" href="https://cdn.staticfile.org/photoswipe/4.1.3/photoswipe.min.css">
<link rel="stylesheet" href="https://cdn.staticfile.org/photoswipe/4.1.3/default-skin/default-skin.min.css">
<script src="https://cdn.staticfile.org/photoswipe/4.1.3/photoswipe.min.js"></script>
<script src="https://cdn.staticfile.org/photoswipe/4.1.3/photoswipe-ui-default.min.js"></script>

<script>
    function viewer_init() {
        let pswpElement = document.querySelectorAll('.pswp')[0];
        let $imgArr = document.querySelectorAll(('.article-entry img:not(.reward-img)'))

        $imgArr.forEach(($em, i) => {
            $em.onclick = () => {
                // slider展开状态
                // todo: 这样不好，后面改成状态
                if (document.querySelector('.left-col.show')) return
                let items = []
                $imgArr.forEach(($em2, i2) => {
                    let img = $em2.getAttribute('data-idx', i2)
                    let src = $em2.getAttribute('data-target') || $em2.getAttribute('src')
                    let title = $em2.getAttribute('alt')
                    // 获得原图尺寸
                    const image = new Image()
                    image.src = src
                    items.push({
                        src: src,
                        w: image.width || $em2.width,
                        h: image.height || $em2.height,
                        title: title
                    })
                })
                var gallery = new PhotoSwipe(pswpElement, PhotoSwipeUI_Default, items, {
                    index: parseInt(i)
                });
                gallery.init()
            }
        })
    }
    viewer_init()
</script> 
<!-- MathJax -->

<!-- Katex -->

<!-- busuanzi  -->
 
<script src="/js/busuanzi-2.3.pure.min.js"></script>
 
<!-- ClickLove -->

<!-- ClickBoom1 -->

<!-- ClickBoom2 -->

<!-- CodeCopy -->
 
<link rel="stylesheet" href="/css/clipboard.css">
 <script src="https://cdn.staticfile.org/clipboard.js/2.0.10/clipboard.min.js"></script>
<script>
  function wait(callback, seconds) {
    var timelag = null;
    timelag = window.setTimeout(callback, seconds);
  }
  !function (e, t, a) {
    var initCopyCode = function(){
      var copyHtml = '';
      copyHtml += '<button class="btn-copy" data-clipboard-snippet="">';
      copyHtml += '<i class="ri-file-copy-2-line"></i><span>COPY</span>';
      copyHtml += '</button>';
      $(".highlight .code pre").before(copyHtml);
      $(".article pre code").before(copyHtml);
      var clipboard = new ClipboardJS('.btn-copy', {
        target: function(trigger) {
          return trigger.nextElementSibling;
        }
      });
      clipboard.on('success', function(e) {
        let $btn = $(e.trigger);
        $btn.addClass('copied');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-checkbox-circle-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPIED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-checkbox-circle-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
      clipboard.on('error', function(e) {
        e.clearSelection();
        let $btn = $(e.trigger);
        $btn.addClass('copy-failed');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-time-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPY FAILED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-time-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
    }
    initCopyCode();
  }(window, document);
</script>
 
<!-- CanvasBackground -->

<script>
  if (window.mermaid) {
    mermaid.initialize({ theme: "forest" });
  }
</script>


    
    

  </div>
</body>

</html>