<!DOCTYPE html>


<html lang="en">
  

    <head>
      <meta charset="utf-8" />
        
      <meta name="description" content="joshua" />
      
      <meta
        name="viewport"
        content="width=device-width, initial-scale=1, maximum-scale=1"
      />
      <title>project_notes |  Mingwei’s Blog</title>
  <meta name="generator" content="hexo-theme-ayer">
      
      <link rel="shortcut icon" href="/favicon.ico" />
       
<link rel="stylesheet" href="/dist/main.css">

      
<link rel="stylesheet" href="/css/fonts/remixicon.css">

      
<link rel="stylesheet" href="/css/custom.css">
 
      <script src="https://cdn.staticfile.org/pace/1.2.4/pace.min.js"></script>
       
 

      <link
        rel="stylesheet"
        href="https://cdn.jsdelivr.net/npm/@sweetalert2/theme-bulma@5.0.1/bulma.min.css"
      />
      <script src="https://cdn.jsdelivr.net/npm/sweetalert2@11.0.19/dist/sweetalert2.min.js"></script>

      <!-- mermaid -->
      
      <style>
        .swal2-styled.swal2-confirm {
          font-size: 1.6rem;
        }
      </style>
    <link rel="alternate" href="/atom.xml" title="Mingwei’s Blog" type="application/atom+xml">
</head>
  </html>
</html>


<body>
  <div id="app">
    
      
    <main class="content on">
      <section class="outer">
  <article
  id="post-project-notes"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h1 class="article-title sea-center" style="border-left:0" itemprop="name">
  project_notes
</h1>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2023/06/19/project-notes/" class="article-date">
  <time datetime="2023-06-19T08:35:01.000Z" itemprop="datePublished">2023-06-19</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/Courses/">Courses</a>
  </div>
  
<div class="word_count">
    <span class="post-time">
        <span class="post-meta-item-icon">
            <i class="ri-quill-pen-line"></i>
            <span class="post-meta-item-text"> Word count:</span>
            <span class="post-count">19.6k</span>
        </span>
    </span>

    <span class="post-time">
        &nbsp; | &nbsp;
        <span class="post-meta-item-icon">
            <i class="ri-book-open-line"></i>
            <span class="post-meta-item-text"> Reading time≈</span>
            <span class="post-count">74 min</span>
        </span>
    </span>
</div>
 
    </div>
      
    <div class="tocbot"></div>




  
    <div class="article-entry" itemprop="articleBody">
       
  <h1 id="Master-Dissertation"><a href="#Master-Dissertation" class="headerlink" title="Master Dissertation"></a>Master Dissertation</h1><h2 id="week1"><a href="#week1" class="headerlink" title="week1"></a>week1</h2><h3 id="Microservice-Docker-Explanation"><a href="#Microservice-Docker-Explanation" class="headerlink" title="Microservice, Docker Explanation:"></a><strong>Microservice, Docker Explanation:</strong></h3><p><strong>Service Grid</strong> and <strong>Microservice Communication</strong>: The Service Grid is an infrastructure layer that handles service-to-service communication. As the number of microservices increases, so does the complexity of communication between services. Service Grids such as Istio and Linkerd help solve this problem, but there is still much room for research and exploration, including communication efficiency, security, observability, and control.</p>
<p><strong>Container orchestration</strong> and <strong>scheduling</strong>: With the growing popularity of containerized applications, how to effectively manage and schedule these containers has become an important issue. Although Kubernetes has become the de facto standard, further research is needed on how to optimize scheduling strategies, how to save resources while ensuring performance, and how to perform container scheduling in multi-cloud environments.</p>
<p><strong>Performance</strong> and <strong>Scalability of Microservices</strong>: With the widespread adoption of microservice architectures, how to improve the performance and scalability of microservices is an important research issue. This includes how to design an efficient microservice architecture, how to optimize the performance of microservices, and how to effectively scale up and down microservices.</p>
<p><strong>Security of containers</strong> and <strong>microservices</strong>: Due to the dynamic and decentralized nature of containers and microservices, their security becomes an important research issue. This includes how to ensure the isolation of containers, how to protect the communication between microservices, and how to prevent malicious code from running in container and microservice environments, etc.</p>
<p><strong>Testing</strong> and <strong>verification of microservices</strong>: The independence and dynamic nature of microservices brings new challenges for testing and verification. How to conduct effective microservice testing, how to verify the correctness of microservices, and how to perform continuous integration and continuous deployment of microservices are all issues that need to be studied.</p>
<p><strong>Fault detection</strong> and <strong>recovery</strong>: In a distributed environment, fault detection and recovery is a very important issue. This includes how to quickly detect faults, how to accurately locate the cause of faults, and how to automatically restore services.</p>
<h3 id="How-and-why-decoupling"><a href="#How-and-why-decoupling" class="headerlink" title="How and why decoupling?"></a><strong>How and why decoupling?</strong></h3><p>Decoupling and transforming a project into a microservice architecture while containerizing it using Docker can improve system scalability, maintainability, and disaster recovery. The following are some basic steps:</p>
<ol>
<li>Determine microservice boundaries: The first step is to determine which microservices to decompose the large monolithic application into. This process requires understanding the business logic and identifying modules that can run independently and scale independently. A good microservice should be business-driven and can perform a specific business function independently.</li>
</ol>
<!---->

<ol start="2">
<li>Create inter-service communication mechanisms: In a microservice architecture, services need to communicate with each other over the network. You can choose to use REST, gRPC, or message queues for communication.</li>
</ol>
<!---->

<ol start="3">
<li>Designing data persistence: Each microservice should have its own independent database to reduce the coupling between services. But this also needs to address the issue of data consistency.</li>
</ol>
<!---->

<ol start="4">
<li>Build microservices: For each microservice, you can choose the programming language and framework that best suits the business logic of that service for development.</li>
</ol>
<!---->

<ol start="5">
<li>Create Docker containers: Pack each microservice into a Docker container. Each container contains all the dependencies and environments needed to run a microservice, which ensures that the microservice will run stably in any environment.</li>
</ol>
<!---->

<ol start="6">
<li>Orchestrate with Docker Compose or Kubernetes: These tools can help manage and deploy your Docker containers, as well as handle service discovery, load balancing, fault recovery, networking, and security.</li>
</ol>
<!---->

<ol start="7">
<li>Implement Continuous Integration and Continuous Deployment (CI&#x2F;CD): Automating builds, tests, and deployments can greatly improve development speed and software quality.</li>
</ol>
<p>The main benefits of doing so are as follows:</p>
<ol>
<li>Scalability: When the system load increases, services with higher demand can be scaled individually without the need to scale as a whole.</li>
</ol>
<!---->

<ol start="2">
<li>Maintainability: Each service runs independently, with a small code base that is easier to understand and modify.</li>
</ol>
<!---->

<ol start="3">
<li>Fault isolation: If something goes wrong with one service, it will not affect other services, reducing the risk of system failure.</li>
</ol>
<!---->

<ol start="4">
<li>Fast iteration: Each microservice can be deployed independently, making it faster to develop and bring new features online.</li>
</ol>
<!---->

<ol start="5">
<li>Technology diversity: Each microservice can choose the technology stack that best suits its business needs.</li>
</ol>
<p>Benefits from containerization: Using Docker containers simplifies the deployment process, ensures software consistency across environments, and provides better.</p>
<h3 id="Fog-computing"><a href="#Fog-computing" class="headerlink" title="Fog computing:"></a><strong>Fog computing:</strong></h3><p>Fog computing is a computing architecture in which a series of nodes receives data from IoT devices in real time. These nodes perform real-time processing of the data that they receive, with millisecond response time. The nodes periodically send analytical summary information to the cloud</p>
<h3 id="Projects-ideas"><a href="#Projects-ideas" class="headerlink" title="Projects ideas:"></a><strong>Projects ideas:</strong></h3><p><strong>Docker and distributed architecture application in cloud computing platform.</strong></p>
<p><strong>Decouple a project into microservices architecture (Monometer -&gt; microservice, use brownfield projects).</strong></p>
<p>Make sure every service we have is <strong>high cohesion, and low coupling</strong>.</p>
<p><strong>Avoid underserving</strong>. The system says no more than four calls. This ensures a moderate level of service. In addition, it is important to think about the team in terms of making the team light enough to decouple microservices from each other. From the above aspects, to avoid the problem of microservices too small.</p>
<p>Some open source manometer projects: <span style="color: rgb(65, 131, 196)"><a target="_blank" href="https://github.com/BroadleafCommerce/BroadleafCommerce" rel="noopener noreferrer nofollow noopener">BroadleafCommerce</a></span>, <span style="color: rgb(65, 131, 196)"><a target="_blank" href="https://github.com/jhipster/generator-jhipster" rel="noopener noreferrer nofollow noopener">https://github.com/jhipster/generator-jhipster</a></span></p>
<p>Decompose by business capability model&#x2F;Decompose by subdomain pattern (DDD).</p>
<h2 id="week2"><a href="#week2" class="headerlink" title="week2"></a>week2</h2><h3 id="Paper-review"><a href="#Paper-review" class="headerlink" title="Paper review"></a>Paper review</h3><p>Summary and baselines</p>
<p><a href="zotero://note/u/F2ET4VTB/" rel="noopener noreferrer nofollow" zhref="zotero://note/u/F2ET4VTB/" ztype="znotelink" class="internal-link">Will_edge_autoscaling</a></p>
<p><a href="zotero://note/u/LLKLWX39/" rel="noopener noreferrer nofollow" zhref="zotero://note/u/LLKLWX39/" ztype="znotelink" class="internal-link">ML-based scaling management for kube</a></p>
<p><a href="zotero://note/u/ZRBM8KGM/" rel="noopener noreferrer nofollow" zhref="zotero://note/u/ZRBM8KGM/" ztype="znotelink" class="internal-link">PBScaler: A Bottleneck-aware Autoscaling Framework for Microservice-based Applications</a></p>
<p><a href="zotero://note/u/ZJ4GRYZR/" rel="noopener noreferrer nofollow" zhref="zotero://note/u/ZJ4GRYZR/" ztype="znotelink" class="internal-link">Microscaler: Automatic Scaling for Microservices with an Online Learning Approach”</a></p>
<p><a href="zotero://note/u/NL4AQ6DY/" rel="noopener noreferrer nofollow" zhref="zotero://note/u/NL4AQ6DY/" ztype="znotelink" class="internal-link">Autopilot: workload autoscaling at Google</a></p>
<p><a href="zotero://note/u/YIAM47M4/" rel="noopener noreferrer nofollow" zhref="zotero://note/u/YIAM47M4/" ztype="znotelink" class="internal-link">Adaptive scaling of Kubernetes pods</a></p>
<p><a href="zotero://note/u/E4TSY6WJ/" rel="noopener noreferrer nofollow" zhref="zotero://note/u/E4TSY6WJ/" ztype="znotelink" class="internal-link">Proactive Autoscaling for Edge Computing Systems with Kubernetes</a></p>
<p><a href="zotero://note/u/QEET6TKX/" rel="noopener noreferrer nofollow" zhref="zotero://note/u/QEET6TKX/" ztype="znotelink" class="internal-link">SHOWAR: Right-Sizing And Efficient Scheduling of Microservices</a></p>
<h3 id="Relative-project"><a href="#Relative-project" class="headerlink" title="Relative project"></a>Relative project</h3><p><a target="_blank" rel="noopener" href="https://github.com/jthomperoo/custom-pod-autoscaler">https://github.com/jthomperoo/custom-pod-autoscaler</a></p>
<p><strong>Custom Pod Autoscaler</strong></p>
<p>HPA cons: hard coded algorithm, CPA provides you flexibility in my scaling.</p>
<h2 id="Week3"><a href="#Week3" class="headerlink" title="Week3"></a>Week3</h2><p>Autopilot&#x2F; LOTUS</p>
<p>CPA</p>
<h2 id="Week4"><a href="#Week4" class="headerlink" title="Week4"></a>Week4</h2><p>PPA&#x2F;PBScaler&#x2F;LOTUS&#x2F;Autopilot</p>
<p>Let’s start with PPA</p>
<p><strong>摘要</strong></p>
<p>随着物联网和5G技术的出现，边缘计算范式以更好的可用性、延迟控制和性能发挥着越来越重要的作用。然而，现有的边缘计算应用程序的自动缩放工具不能有效地利用边缘系统的异构资源，从而为性能改进留下了空间。在这项工作中，我们为Kubernetes上的边缘计算应用程序提出了一个主动Pod Autoscaler (PPA)。提议的PPA能够使用多个用户定义&#x2F;自定义指标提前预测工作负载，并相应地扩展和缩小边缘计算应用程序。在一个cpu密集型边缘计算应用实例中，进一步对PPA进行了优化和评估。可以得出结论，所提出的PPA在资源利用效率和应用程序性能方面都优于Kubernetes默认的pod自动缩放器。文章还强调了拟议购电协议未来可能的改进。</p>
<p><strong>一</strong></p>
<p>在过去的几十年里，云计算应用在各种广泛的领域中越来越受欢迎[4,18]。云计算供应商为用户提供按需可用的大量资源，包括计算单元、存储、网络设备，甚至服务和应用程序。云计算已经被证明在商业和技术方面都是成功的，并且这种方法为许多流行的应用程序(例如Netflix, DropBox, Spotify)提供了动力[13,15]。然而，云计算存在应用程序延迟的问题，这主要受限于客户端与数据中心之间的地理距离和网络带宽[12]。因此，云计算不能完全满足对延迟敏感的应用程序(例如视频游戏流、实时数据分析)的需求。</p>
<p>边缘计算是解决传统云计算延迟问题的一种很有前途的方法[14]，它将对延迟敏感的计算和数据存储移动到靠近网络边缘的客户端位置。边缘计算具有较低的延迟、带宽占用和开销，在实现智慧城市、智能电网、智能交通等方面发挥着重要作用[11]。</p>
<p>在现实场景中，云计算和边缘计算应用程序的自动伸缩是必不可少的[3,20]。随着工作负载的变化，自动伸缩工具会动态调整资源量，以保持每个计算&#x2F;存储单元的平均工作负载稳定。自动缩放为应用程序提供了更好的容错性、高可用性、高效的能耗和成本管理。</p>
<p>对于云计算，HPA作为Kubernetes提供的本地服务被广泛使用，Kubernetes是大多数云平台上事实上的云框架[8]。HPA以CPU利用率为衡量工作负载的指标，使用式1所示的算法以响应式方式扩展云应用程序。</p>
<p>![截屏2023-07-04 18.41.15](..&#x2F;images&#x2F;:Users:joshua:Library:Application Support:typora-user-images:截屏2023-07-04 18.41.15.png)</p>
<p>然而，对于边缘计算，自动缩放是一个更复杂的问题[19]。尽管HPA在许多云计算案例中简单有效，但它并不完全能够自动扩展边缘计算应用，原因有三个:</p>
<p>HPA不是专门为边缘计算环境设计的，不知道异构边缘资源的约束和能力;</p>
<p>HPA仅考虑CPU利用率来估计工作负载。然而，对于边缘计算应用程序，在扩展应用程序时，有关系统的其他信息(例如作业队列、I&#x2F;O、请求速率)也是必不可少的;</p>
<p>HPA是基于规则的，不可编程的，服务提供商很难定制HPA来满足他们对边缘计算应用的特定需求</p>
<p>一种很有前途的方法是为边缘计算应用程序开发一个主动的自动缩放器，该自动缩放器支持多个度量和可定制的算法。然而，开发这样的自动缩放器是具有挑战性的。从理论上讲，由于边缘资源的异质性和局限性，预测边缘系统的工作负载和扩展pod形成了一个时间序列分析和多目标优化的混合问题。实际上，从不同的来源收集多个度量标准并以统一的方式组织依赖于各种库的自定义算法是一个复杂的多框架工程问题。在这项工作中，我们提出了一个多指标支持和可定制的主动pod自动缩放器。自动扩展器能够收集多个指标，预测工作负载并提前扩展目标应用程序。此外，它允许用户自定义他们自己的扩展策略和预测模型，以更好地适应他们的应用程序。这项工作的主要贡献包括:</p>
<p><strong>(1)为自动缩放边缘计算应用引入主动工作流。</strong></p>
<p><strong>(2)在Kubernetes上实现多指标支持和可定制的自动缩放器。</strong></p>
<p><strong>(3)提供一个示例应用程序，以演示所建议的自动缩放器的性能。</strong></p>
<p>本文的其余部分组织如下。相关文献在第2节中进行了回顾。在第3节中，说明了本工作中边缘系统环境的设计。在第4节中，详细解释了所提出的自动缩放器的体系结构和算法。第5节和第6节介绍了所建议的自动缩放器的实验设计和结果。第7节总结了工作，并强调了进一步可能的改进。</p>
<p><strong>二</strong></p>
<p>考虑到HPA作为一个基准，许多研究工作已经开始探索HPA的替代方案，以用于托管在容器上的云&#x2F;边缘应用程序。在本节中，将回顾有关被动和主动自动缩放技术的相关工作。此外，我们提出的主动Pod自动缩放器的必要性和其独特的功能进行了解释。</p>
<p><strong>2.1</strong></p>
<p>2019年，Fan等人报道了一种容器系统架构，提供了更高的自动缩放效率[22]。2020年，Salman和Marko的一篇文章探讨了除了CPU利用率之外应该考虑的其他关键因素[17]。可以肯定的是，为了更好地自动扩展云系统，除了CPU利用率之外，还需要多个指标。无功自缩放器的一个主要缺点是控制延迟。虽然一旦工作负载发生变化，容器就会被扩展，但是容器的初始化或终止需要时间。</p>
<p><strong>2.2</strong></p>
<p>为了改进响应式pod自动扩展器，它有望预测工作负载并提前做出扩展决策，即主动&#x2F;预测自动扩展。2016年，Yang等人提出了一种基于时间序列分析预测容器CPU使用情况的主动自缩放算法CRUPA[9]。另一个例子来自Tian等人，他们在2017年报告了一个预测自动缩放框架[21]。为了提供更好的服务质量，提出了一种结合CPU利用率预测和服务水平协议的混合自扩展策略。机器学习模型在时间序列分析中得到了很多关注[16]，一些报道的主动自动标度器是基于机器学习模型的。2020年，Mahmoud, Imtiaz和Mohammad提出了一种基于机器学习的主动自动缩放器，它利用LSTM和多个指标来预测工作负载[6]。虽然有一些关于云系统的主动自动缩放的工作，但边缘计算系统的主动自动缩放很少。据我们所知，只有一篇文章报道了边缘系统的主动自动缩放[1]。建立了预训练的神经网络模型，并将其作为运行系统中CPU利用率的预测模型。预测的CPU指标用于估计副本的数量。表1比较了相关工作和我们提出的方法。我们提出的主动Pod自动缩放器(PPA)具有以下特点:</p>
<p>•考虑到异构资源的限制和约束，这是少数关注边缘计算应用程序自动缩放的研究之一。</p>
<p>•支持多个指标(CPU, RAM, I&#x2F;O利用率)和自定义指标来自动扩展应用程序，为工作负载估计和预测提供替代指标。尽管CPU利用率在许多情况下能够预测工作负载，但一些应用程序需要多个或特定于应用程序的指标来做出扩展决策。</p>
<p>•PPA灵活且与模型无关。与其他具有固定预测模型的主动pod自动缩放器不同，拟议的PPA支持自定义模型和多个模型框架(例如TensorFlow, statmodels等)。用户可以将自己的模型注入到PPA中，以获得适合自己应用的最佳性能。</p>
<p>•购电协议可以考虑信心因素。如果注入的模型是贝叶斯模型，对每个预测产生置信度&#x2F;不确定性估计，那么所提出的自动标度器只有在预测置信度超过预设置信度阈值时才会主动工作，否则它会被动工作</p>
<p><strong>三</strong></p>
<p>现在详细介绍了所考虑的云和边缘环境的设置。</p>
<p><strong>3.1 边缘计算的环境</strong></p>
<p>![截屏2023-07-04 19.18.26](..&#x2F;images&#x2F;:Users:joshua:Library:Application Support:typora-user-images:截屏2023-07-04 19.18.26.png)</p>
<p>![截屏2023-07-04 19.19.38](..&#x2F;images&#x2F;:Users:joshua:Library:Application Support:typora-user-images:截屏2023-07-04 19.19.38.png)</p>
<p>图1显示了我们为Kubernetes连接的云&#x2F;边缘计算环境编排的拓扑结构。表2介绍了系统中节点分配的资源。不同节点分配的资源有限且大小不一，而云节点拥有更强的计算能力和更大的内存资源。该系统描绘了一个典型边缘计算环境的真实世界模型。</p>
<p>![截屏2023-07-04 19.20.41](..&#x2F;images&#x2F;:Users:joshua:Library:Application Support:typora-user-images:截屏2023-07-04 19.20.41.png)</p>
<p><strong>3.2 集群组件</strong></p>
<p>除了Kubernetes核心之外，集群还包含三个用于系统监控的逻辑组件，包括导出器、Prometheus堆栈和自动缩放器。集群的监控系统对于成功运行所建议的云&#x2F;边缘计算框架起着至关重要的作用。该系统基于Prometheus[5]，这是云计算和边缘计算环境中最流行的框架之一。不同类型的导出器负责生成不同的度量标准。在考虑的边缘计算环境中，节点导出器部署在每个节点上用于节点级指标，并为用户部署可自定义导出器以生成&#x2F;提取用户自定义指标(例如请求率，排队任务数等)作为自定义指标。普罗米修斯堆栈由三部分组成——普罗米修斯、Grafana和普罗米修斯适配器。指标由Prometheus从出口商收集，并使用Grafana进行可视化。收集到的指标也由Prometheus Adapter在标准API中公开，以便其他pod能够以统一的方式获取它们。从Prometheus Adapter，自动扩展器获取所有类型的所需指标，评估所需副本的数量，并向Kubernetes主控制面板发出扩展决策请求。Kubernetes负责处理扩展请求和在节点上调度新的pod。</p>
<p><strong>四</strong></p>
<p>在本节中，介绍了所提出的主动Pod自动缩放器的体系结构和算法。首先阐述了PPA的结构和工作流程。然后，对PPA各组成部分的详细算法进行了推导和说明。</p>
<p><strong>4.1 架构</strong></p>
<p>![截屏2023-07-04 19.32.26](..&#x2F;images&#x2F;:Users:joshua:Library:Application Support:typora-user-images:截屏2023-07-04 19.32.26.png)</p>
<p>图2显示了提议的主动pod自动缩放器的结构。PPA由三个组件(Formulator、Evaluator和Updater)组成，在两个循环中工作(控制循环和模型更新循环)，并维护两个文件(度量历史文件和模型文件)。PPA的初始化需要将预训练的种子模型作为初始模型文件注入框架中。</p>
<p>在每个控制循环中，PPA负责使用收集到的指标扩展目标pod。Formulator从Prometheus Adapter获取原始指标，并对其进行预处理。制定的度量存储在度量历史文件中，并传递给评估者。然后，Evaluator从模型文件中加载模型，预测所需副本的数量，并向Kubernetes控制面板发出缩放请求。</p>
<p>在每个模型更新循环中，Updater从度量历史文件中加载训练数据，更新模型，删除度量历史文件，并将模型重新保存到模型文件中。有了Updater，用于预测的模型就可以针对新的工作负载模式不断更新。</p>
<p><strong>4.2算法</strong></p>
<p><strong>4.2.1 评估器evaluator</strong></p>
<p>算法1描述了评估器的工作原理。对于每个PPA，必须将一个关键指标设置为工作负载的估计器，注入的预测模型使用收集的指标来预测关键指标。为了从预测的关键指标中获得所需的副本数量，应该定义一个静态策略。在本工作中，使用第1节中描述的基于阈值的HPA算法作为默认的静态策略。但是，静态策略是可定制的，用户可以在PPA中注入自己的策略。</p>
<p>![截屏2023-07-04 19.41.37](..&#x2F;images&#x2F;:Users:joshua:Library:Application Support:typora-user-images:截屏2023-07-04 19.41.37.png)</p>
<p><strong><code>model.isBayesian()</code> 是检查模型是否为贝叶斯模型的条件。贝叶斯模型是一种统计模型，它使用贝叶斯定理进行推断和预测。在这段代码中，如果模型是贝叶斯模型并且预测的置信度低于阈值，就会选择使用当前的关键度量指标而不是模型预测的结果。</strong></p>
<p><strong>4.2.2 模型的协议</strong></p>
<p>所有满足以下协议的时间序列模型都可以注入进行指标预测:</p>
<p>(1)时间窗口大小:所有模型的时间窗口大小固定为1个单位，表明模型使用上一个回路的指标预测下一个控制回路的工作量。这是由新pod的初始化时间成本决定的，它通常需要不到一个时间间隔的控制循环。</p>
<p>(2)输入输出指标:模型的指标应按以下顺序输入[CPU, RAM，网络输入，网络输出，自定义指标]。该模型应该预测所有输入指标，但只有一个被设置为关键指标。</p>
<p><strong>4.2.3升级器的模型更新策略Model Update Policy of the Updater</strong></p>
<p>虽然Updater的工作流程是固定的，但我们提出了3种不同的策略来更新种子模型(称为模型更新策略):</p>
<p>(1)不重新训练模型:在整个执行过程中使用注入的种子模型而不更新。如果种子模型在稳定的工作负载下能够产生令人满意的结果，则无需定期更新模型，成本较大;</p>
<p>(2)从头开始重新训练模型:在每个模型更新循环中，Updater丢弃旧模型并从头开始训练具有与种子模型相同架构的新模型。在不同日子的工作负载变化很大的情况下，基于旧数据的模型不一定适合未来几天的工作负载模式;</p>
<p>(3)更新模型:使用上一个模型更新循环的数据对旧模型进行多几个epoch的再训练。在许多情况下，模式的工作负载确实会发生变化，但变化不大，并且可以将旧模型用作更新过程的起点。</p>
<p>这里我们提供了三个选项，对于不同的应用程序和不同的工作负载模式，最佳策略可能不同。</p>
<p><strong>五. 实验</strong></p>
<p>实验的目的是优化所提出的主动Pod自动缩放器的示例应用，并与HPA进行比较，验证其性能。在本节中，首先介绍示例应用程序和工作负载的生成。然后详细介绍了PPA优化和评价的实验细节。</p>
<p><strong>5.1 示例应用</strong></p>
<p>![截屏2023-07-06 12.11.29](..&#x2F;images&#x2F;:Users:joshua:Library:Application Support:typora-user-images:截屏2023-07-06 12.11.29.png)</p>
<p><strong>5.1.1 拓扑图</strong></p>
<p>图3显示了托管在边缘计算集群上的示例应用程序的体系结构。示例应用程序分布在一个云和两个边缘区域中。在每个区域，都部署一些支持性的静态pod和服务，它们是固定的，不是为可扩展而设计的。只有每个区域中的worker pods才是自动缩放器要缩放的目标。</p>
<p><strong>5.1.2 工作流和作业</strong> </p>
<p>在示例应用程序中，定义了两种不同类型的任务。第一种是对长度为3000的随机数组进行排序(称为sort task)，复杂度为𝑛log𝑛;第二种是计算维数为1000 × 1000的随机矩阵的特征值(称为eigen task)，复杂度为𝑛3。所有请求都是从设备生成的，它们到达最靠近其位置的边缘的入口点。每个请求要么是排序任务，要么是特征任务。具有排序任务的任务计算成本不高，由边缘工作者处理，而具有特征任务的任务由于计算成本高而转发给云工作者。本工作中的示例应用程序是模拟典型的cpu密集型应用程序，这些应用程序在一般和科学计算中都很常见(例如天气预报、搜索算法、音频&#x2F;视频处理等)。基于示例应用的结论具有通用性。</p>
<p><strong>5.2 工作负载生成</strong></p>
<p>本工作中考虑了两种不同的工作负载，即随机存取和美国国家航空航天局(NASA)数据集。它们在下文中有描述。</p>
<p><strong>5.2.1随机访问</strong></p>
<p>如图算法2所示，Random Access的设计是为了生成随机工作负载进行优化实验。Sort和Eigen任务分别以0.9和0.1的概率生成，以模拟大多数成本低的请求在边缘处理，而成本高的任务在云中完成。通过定期使用3种不同的工作负载模式(即轻、中、重)访问应用程序，自动缩放器有望覆盖实际使用中可能出现的大多数情况。![截屏2023-07-06 12.25.27](..&#x2F;images&#x2F;:Users:joshua:Library:Application Support:typora-user-images:截屏2023-07-06 12.25.27.png)</p>
<p><strong>5.2.2 NASA数据集</strong></p>
<p>NASA数据集用于模拟真实世界的访问[10]，用于评估实验。所有的访问记录都是由NASA肯尼迪航天中心的WWW服务器收集的，每个日志都包含其访问时间戳。通过累积每分钟的访问请求来预处理原始日志文件，并使用聚合的日志数量向应用程序发出请求。包含2个月记录的数据集的所有请求的综合实验集将非常耗时。</p>
<p>在这项工作中，从数据集中选择2天的子集进行实验。同时，将请求数调整到适当的规模，使峰值工作负载不超过实验边缘环境的资源限制。</p>
<p><strong>5.3 Experiments for optimization</strong></p>
<p>对PPA的三个超参数进行了优化，包括工作量预测模型、更新策略和关键指标。优化问题如式2所示。其中，𝛾为应用程序的响应时间，𝑊为浪费资源的总和，𝑀为预测模型，𝑈为模型更新策略，𝐾为关键指标Key metric，A为目标应用, Rp是分配给pod p的资源, 𝑃𝑛是在节点𝑛上托管的所有pod的集合, 𝑁是所有节点的集合。在这里，目标应用程序A是固定的，并且要优化𝑀、𝑈、𝐾以最小化𝛾和𝑊。</p>
<p>![截屏2023-07-06 13.19.08](..&#x2F;images&#x2F;:Users:joshua:Library:Application Support:typora-user-images:截屏2023-07-06 13.19.08.png)</p>
<p><strong>5.3.1 预测模型优化</strong></p>
<p>针对实例应用，对不同的指标预测模型进行了比较和优化，并以自回归移动平均(ARMA)模型和长短期记忆(LSTM)模型为典型模型。</p>
<p>实验采用ARMA(1,1,1)，表示其移动平均部分阶数和自回归部分阶数均设为1，模型时间窗为1。ARMA模型的超参数是根据收集到的数据预先选择的。</p>
<p>我们使用的LSTM模型由一个50个神经元的LSTM层和一个由ReLu函数激活的全连接层[2]组成。输出层的形状被设置为5，以适应所有未来的指标。LSTM模型的损失函数为均方误差(Mean Squared Error, MSE)，优化器为Adam optimizer[7]。</p>
<p>这两个模型都使用在单个不受约束的节点上运行示例应用程序10个小时并使用Random Access生成的工作负载收集的数据进行预训练。使用这两个模型对示例应用程序进行了200分钟的自动伸缩，并比较了CPU利用率的预测值和实际值。</p>
<p><strong>5.3.2 优化Update策略</strong></p>
<p>如4.2.3节所介绍的，提出并比较了3种不同的Updater方法。在本实验中，预训练的LSTM模型作为种子模型，并将CPU利用率定义为关键指标。为了缩短实验所需的时间，将模型更新循环的时间间隔设置为1小时。示例应用程序运行200分钟，每个PPA使用不同的更新策略自动缩放，并收集CPU利用率的预测值和实际值。</p>
<p><strong>5.3.3 关键指标的优化</strong></p>
<p>在本实验中，将所有pod的请求率或CPU利用率之和作为关键指标进行比较。同样，示例应用程序运行200分钟，每个PPA使用Random Access生成的工作负载自动缩放。由于关键指标的差异，不可能将两个ppa与预测指标进行定量比较。相反，将所有请求的响应时间和由两个ppa自动缩放的系统空闲资源进行比较，以量化两个ppa的性能。</p>
<p><strong>5.4 评价实验</strong></p>
<p>利用最优超参数对优化后的PPA进行真实场景评价。PPA通过最佳配置自动缩放，应用程序可以使用缩放后的NASA数据集的工作负载运行48小时。通过比较请求的响应时间和空闲资源，量化性能。应用程序的另一次运行是使用完全相同的配置进行的，这些配置由Horizontal Pod Autoscaler自动缩放，作为PPA的基线.</p>
<p><strong>6结果与讨论</strong></p>
<p>结果将在下文中提出和讨论。首先给出超参数优化结果，然后在已部署的场景中进行评估。</p>
<p><strong>6.1预测模型优化</strong></p>
<p>两种不同模型的PPA结果如图4所示。观察结果表明，两个模型都能够捕捉到CPU利用率的趋势，而ARMA模型在拟合方面稍好一些。但从数量上看，LSTM模型预测的MSE为53240.972,ARMA模型预测的MSE为96867.631，后者要大得多。这表明，在预测CPU利用率时，ARMA模型提供了显著的变化，而<strong>LSTM模型</strong>能够产生相对更准确的预测。可以得出结论，LSTM在预测示例应用程序的CPU利用率方面优于ARMA模型。</p>
<p>![截屏2023-07-06 13.49.25](..&#x2F;images&#x2F;:Users:joshua:Library:Application Support:typora-user-images:截屏2023-07-06 13.49.25.png)</p>
<p><strong>6.2优化升级策略</strong></p>
<p>图5对具有不同策略的三个ppa进行了比较。采用策略1、策略2和策略3的PPA产生的利用率预测MSE分别为64769.882、42180.437和30994.449，表明策略3在提出的模型更新策略中表现最好。我们得出的结论是，<strong>策略3</strong>在每个模型更新循环中使用新收集的指标重新训练模型，为示例应用程序提供了优于其他策略的最佳性能。</p>
<p>![截屏2023-07-06 13.59.09](..&#x2F;images&#x2F;:Users:joshua:Library:Application Support:typora-user-images:截屏2023-07-06 13.59.09.png)</p>
<p><strong>6.3关键指标的优化</strong></p>
<p>在示例应用程序上比较PPA的两个关键指标，即请求率和CPU利用率。请求的响应时间和空闲资源用于定量地比较ppa的性能。图6显示了使用不同关键指标自动缩放的应用程序上请求的响应时间分布。两个分布的巨大重叠表明两个运行的响应时间非常接近。根据CPU利用率自动缩放的应用程序的平均响应时间为0.5156秒，标准偏差(STD)为0.0421，而根据请求率自动缩放的应用程序的平均响应时间为0.5157秒，标准偏差为0.420。由于时间分布没有显著差异，因此可以得出结论，在响应时间方面自动扩展示例应用程序时，两个关键指标是等效的。(这个图里面的黄线和蓝线估计是基本上重叠了)</p>
<p>![image-20230706141151279](..&#x2F;images&#x2F;:Users:joshua:Library:Application Support:typora-user-images:image-20230706141151279.png)</p>
<p>系统在𝑡时刻的相对空闲资源(RIR_t)(定义为公式3)用于定量地比较两个自动缩放器。具有两个关键指标的ppa的rir如图7所示。CPU请求率的平均RIR为0.317，标准差为0.161;CPU利用率的平均RIR为0.251，标准差为0.092。可以得出结论，以CPU利用率为关键指标的PPA效率更高，浪费的资源更少。此外，RIR的标准偏差较低表明，以CPU利用率为关键指标进行自动缩放时，系统更加稳定。</p>
<p>![截屏2023-07-06 14.17.32](..&#x2F;images&#x2F;:Users:joshua:Library:Application Support:typora-user-images:截屏2023-07-06 14.17.32.png)</p>
<p>尽管具有不同关键指标的两个PPA为请求提供接近的响应时间，但是具有CPU利用率的PPA更节能，系统也更稳定。因此，<strong>CPU利用率</strong>是示例应用程序的最佳关键指标。</p>
<p><strong>6.4实验评价结果</strong></p>
<p>根据最优模型、关键指标和更新策略，对拟议的PPA进行5.4节所述的评估，并将PPA和HPA的性能与请求响应时间和空闲资源进行定量比较。</p>
<p><strong>6.4.1响应时间。</strong></p>
<p>图8显示了由PPA和HPA自动缩放的Sort任务的响应时间分布。HPA自动缩放的应用程序对边缘任务的平均响应时间为0.592秒，标准偏差(STD)为0.067;PPA自动缩放的应用程序的平均响应时间为0.508秒，标准偏差(STD)为0.038。PPA提供的响应时间明显小于HPA, p值小于10−3。此外，PPA提供的分布具有较小的标准差。可以看出，通过PPA自动伸缩的应用程序提供的边缘服务延迟更小，边缘系统更稳定。在特征任务中也观察到类似的结果。HPA和PPA提供的云任务的两个响应时间分布如图9所示。HPA自动缩放的应用程序对边缘任务的平均响应时间为13.382秒，标准差为1.606;PPA自动缩放的应用程序的平均响应时间为13.646秒，标准差为1.576。HPA提供的响应时间显著大于PPA，且p值小于10−3，对于Sort任务的标准差也是如此。因此，与HPA相比，PPA自动扩展的云服务具有更好的性能。</p>
<p>因此，可以得出结论，在边缘计算应用中，所提出的主动Pod Autoscaler在云服务和边缘服务方面都优于默认HPA，具有更低的延迟和更高的访问稳定性。</p>
<p>![截屏2023-07-06 14.22.45](..&#x2F;images&#x2F;:Users:joshua:Library:Application Support:typora-user-images:截屏2023-07-06 14.22.45.png)</p>
<p>![截屏2023-07-06 14.23.25](..&#x2F;images&#x2F;:Users:joshua:Library:Application Support:typora-user-images:截屏2023-07-06 14.23.25.png)</p>
<p><strong>6.4.2空闲资源</strong></p>
<p>图10显示了由PPA和HPA自动缩放的边缘工作节点的相对空闲CPU使用情况。HPA自动缩放的边缘工作线程平均相对空闲CPU为0.3209，标准差为0.1079;PPA自动缩放的边缘工作线程平均相对空闲CPU为0.2988,STD为0.1026。虽然两种自动缩放器的结果在视觉上是相似的，但PPA提供的相对空闲CPU明显小于PPA, p值小于10−3。因此，可以得出结论，PPA自动伸缩的应用程序的边缘工作节点比HPA自动伸缩的应用程序更有效地利用CPU资源。HPA和PPA自动伸缩的云工作节点的相对空闲CPU使用情况如图9所示。HPA自动伸缩的云工作者的平均相对空闲CPU为0.3373，标准差为0.1572;PPA自动伸缩的应用程序的平均相对空闲CPU为0.3098,STD为0.1453。HPA提供的相对空闲CPU明显大于PPA, p值小于10−3。因此，在云节点上，PPA自动伸缩的应用程序比HPA自动伸缩的应用程序浪费的CPU资源更少。综上所述，在请求响应时间和空闲资源方面，本文提出的<strong>Proactive Pod Autoscaler都优于默认的Horizontal Pod Autoscaler</strong>，为边缘计算应用带来更好的性能，获得更多的访问稳定性，并且浪费更少的资源。</p>
<p>![截屏2023-07-06 14.33.27](..&#x2F;images&#x2F;:Users:joshua:Library:Application Support:typora-user-images:截屏2023-07-06 14.33.27.png)</p>
<p><strong>7结论与未来工作</strong></p>
<p>在这项工作中，我们提出了一种基于Kubernetes的边缘计算应用的主动pod自动缩放器(PPA)。PPA能够使用时间序列预测方法提前预测应用程序的到达工作负载，并根据需要伸缩应用程序。以cpu密集型应用程序为例，针对Kubernetes中的内置自动缩放器HPA对自动缩放器进行了优化和评估。可以得出结论，PPA能够更有效地利用资源，并为请求提供更快的响应时间。此外，所提出的自动缩放器具有高度的灵活性和可定制性，因此用户可以调整指标、预测模型和缩放策略，以更好地满足自己应用程序的需求。除了支持多个指标外，用户还可以定义自己的特定于应用程序的指标，以更好地扩展应用程序。这使得ppa能够适应各种类型的应用程序，例如实际使用中的数据密集型应用程序、IO密集型应用程序。拟议的PPA并不完美，因为它需要开发人员手动优化关键指标、模型和策略。在未来的工作中，可以通过自动化超参数优化来改进PPA。一种可能的方法可能涉及使用一组可能的指标运行应用程序，PPA的指定模块使用不同的方法自动建模收集的运行数据。然后可以使用验证技术从候选模型中选择最佳模型。通过这种方式，自动优化的PPA将更容易被开发人员部署和使用。</p>
<p><strong>PBScaler:一个基于微服务的应用程序的瓶颈感知自动伸缩框架</strong></p>
<p><strong>Introduction</strong></p>
<p>随着微服务架构的推进，越来越多的云应用从单片架构向微服务架构迁移[1]、[2]、[3]、[4]、[5]、[6]。这种新架构通过将一个单片应用程序分解为多个微服务，通过HTTP或RPC协议相互通信来减少应用程序耦合[7]。此外，每个微服务都可以由独立的团队独立开发、部署和扩展，从而实现快速的应用程序开发和迭代。然而，外部工作负载的不可预测性和微服务之间交互的复杂性会导致性能下降[8]，[9]，[10]。云提供商必须准备过多的资源来满足应用程序所有者的服务水平目标(service level objective, SLO)，这通常会造成不必要的资源浪费[11]，[12]。因此，满足SLO和最小化资源消耗之间的不平衡成为微服务中资源管理遇到的主要挑战。</p>
<p>微服务自动伸缩指的是根据工作负载变化弹性分配资源的能力[13]。通过利用微服务的弹性特性，自动扩展可以缓解资源成本和性能之间的冲突。然而，微服务的自动伸缩难以在短时间内准确地伸缩性能瓶颈(PB)。由于微服务之间通信的复杂性，PB的性能下降可能会通过消息传递传播给其他微服务[2]，导致同时出现大量异常微服务。我们通过在Google开发的开源微服务应用Online Boutique 1中向特定的微服务注入突发工作负载来证明这一点。图1显示，PB推荐中的性能下降会蔓延到上游微服务，如Checkout和Frontend。为了进一步验证准确扩展PB的重要性，我们进行了压力测试，并分别扩展了不同的微服务。如图2所示，微服务(前端)扩容异常并不能缓解SLO违规。然而，当我们确定并扩展PB推荐时，微服务应用程序的性能得到了改善。不幸的是，定位PBs通常很耗时，偶尔也会出错[14]。</p>
<p>近年来，已经提出了几种方法来在自动扩展之前识别关键的微服务。例如，Kubernetes 2的默认自动缩放器根据计算资源的静态阈值过滤微服务进行直接缩放。Yu等[15]通过计算服务功率来定义弹性缩放的边界，服务功率是第50百分位响应时间(P50)与第90百分位响应时间(P90)之比。此外，Qiu等人[4]引入了一种基于支持向量机的方法，通过分析各种尾部延迟的比率来提取关键路径。尽管这些研究缩小了自动扩展的范围，但它们仍然考虑了可能影响扩展策略的非瓶颈微服务，特别是当应用程序中大量微服务同时异常时。因此，在自动扩展之前，迫切需要精确地定位瓶颈微服务。为了平衡资源消耗和性能，现有的工作采用在线优化算法来寻找接近最优的自动缩放策略。然而，由于自动扩展的可能策略范围很广，这些方法需要大量的尝试，这对于在线应用程序来说是有问题的。例如，Train Ticket3是最大的开源微服务应用程序，由近40个微服务组成。假设每个微服务最多可以有15个副本，确定此应用程序的最佳分配策略无疑是一个np难题，因为最多有1540个可扩展选项。此外，在线优化中反馈回路的持续时间过长，难以实现模型收敛。考虑由在线优化引起的性能下降的潜在风险也很重要。图3显示了突发工作负载对MicroScaler的副本波动和延迟波动的影响[15]，MicroScaler是一种在线自动扩展方法，采用在线贝叶斯优化来寻找总成本的全局最小值。由于在线优化导致频繁的在线尝试创建副本(图3a)，导致振荡和性能下降(图3b)。因此，我们受到启发，设计了一个离线优化过程，由模拟器的反馈推动。</p>
<p>![截屏2023-07-08 15.25.06](..&#x2F;images&#x2F;:Users:joshua:Library:Application Support:typora-user-images:截屏2023-07-08 15.25.06.png)</p>
<p>![截屏2023-07-08 15.26.32](..&#x2F;images&#x2F;:Users:joshua:Library:Application Support:typora-user-images:截屏2023-07-08 15.26.32.png)</p>
<p>本文介绍了PBScaler，这是一个<strong>横向自动扩展框架</strong>，旨在通过识别和解决瓶颈来防止基于微服务的应用程序的性能下降。与之前的工作[11]、[15]所做的针对所有异常微服务优化资源不同，我们提出了TopoRank，一种基于拓扑势理论(TPT)的随机游走算法，用于识别性能瓶颈(PBs)。通过考虑微服务依赖关系和潜在异常，TopoRank提高了瓶颈定位的准确性和可解释性。在通过TopoRank识别PBs后，PBScaler进一步采用<strong>遗传算法</strong>来寻找接近最优的策略。为了避免过度优化引起的应用振荡，该过程离线进行，并由SLO违例预测器指导，该预测器模拟在线应用并向缩放策略提供反馈。本文的主要贡献总结如下:</p>
<p>•我们提出PBScaler，这是一个瓶颈感知自动伸缩框架，旨在防止基于微服务的应用程序中的性能下降。通过精确定位瓶颈，PBScaler可以减少不必要的扩展并加快优化过程。</p>
<p>•我们采用基于遗传算法的离线优化过程来优化资源消耗，同时避免违反SLO。此过程由SLO违规预测器指导，旨在在不中断在线应用程序的情况下在资源消耗和性能之间取得平衡。</p>
<p>•我们在Kubernetes系统中设计和实现PBScaler。为了评估其有效性，我们在两个在线环境中运行的广泛使用的微服务系统上进行了大量的真实世界和模拟工作负载注入实验。实验结果表明，PBScaler比几种最先进的弹性缩放方法性能更好。本文的其余部分组织如下。在第2节中，我们将讨论微服务的瓶颈分析和自动扩展的相关工作。在第3节中，我们详细描述了整个系统。在第4节中，我们给出了评估和实验结果。第五部分总结了我们的工作，并讨论了未来的研究方向。</p>
<p><strong>2 Related work</strong></p>
<p>随着云计算的发展，学术界和工业界提出了许多云资源(如虚拟机或容器)的自扩展方法[16]、[17]、[18]、[19]。然而，由于微服务之间错综复杂的依赖关系，微服务的自动伸缩可能要复杂得多。</p>
<p><strong>2.1 Bottleneck Analysis</strong></p>
<p>近年来，已经开发了许多用于微服务场景瓶颈分析的方法，其中大多数依赖于三种类型的数据:<strong>logs</strong>、<strong>Trace</strong>和<strong>metrics</strong>。</p>
<p>1)<strong>日志</strong>。Jia等[20]和Nandi等[21]首先从正常状态的日志中提取模板和流程，与目标日志进行匹配，过滤掉异常日志。</p>
<p>2)<strong>痕迹</strong>。Trace是一个基于事件跟踪的记录，它再现微服务之间的请求过程。一些研究[22]，[23]，[24]，[25]已经引入使用轨迹来确定瓶颈。Yu等人[22]、[23]结合频谱分析和PageRank算法在trace构建的依赖图上定位瓶颈，Mi等人[24]提出了无监督机器学习原型，学习微服务的模式，过滤异常微服务。然而，使用跟踪可能会干扰代码，并且要求操作人员对微服务的结构有深入的了解。</p>
<p>3)<strong>指标</strong>。一些方法[2]，[26]，[27]利用图随机游走算法来模拟异常的传播过程，然后通过集成度量的统计特征和微服务之间的依赖关系来找到瓶颈。此外，CauseInfer[14]和MicroCause[28]等方法侧重于用因果推理构建指标因果图，这通常涉及指标之间隐藏的间接关系。</p>
<p>由于在监控指标时很少修改工作流代码，因此为微服务收集指标通常比使用跟踪更便宜。此外，使用度量作为主要监控数据可以降低集成瓶颈分析和自动伸缩的成本，因为度量在后一种场景中被广泛使用。尽管这些方法具有优势，但大多数方法在选择异常回溯的起始点时没有偏好。相比之下，我们的方法从具有更大异常潜力的微服务开始随机漫步，加快了收敛速度并提高了瓶颈定位精度。</p>
<p><strong>2.2 Autoscaling for microservices</strong></p>
<p>现有的微服务自动伸缩方法可以分为五类。</p>
<p>**1)基于规则的启发式方法 **KHPA、Libra[29]、KHPA- a[30]和PEMA[31]基于资源阈值和特定规则管理微服务副本的数量。然而，由于不同的微服务对特定资源的敏感性不同，因此需要专业知识来支持这些不同微服务的自动伸缩。</p>
<p><strong>2)基于模型的方法</strong> 可以对微服务进行建模，以预测它们在特定配置和工作负载下的状态。排队论[32]、[33]和图神经网络(GNN)[12]常用来构建微服务的性能预测模型。</p>
<p><strong>3)基于控制理论的方法</strong> [11]，[32] 使用控制理论，SHOWAR[11]动态调整微服务副本，以纠正监控指标和阈值之间的错误。</p>
<p><strong>4)基于优化的方法</strong> 这些方法[15]、[34]在给定当前资源和工作负载的情况下，进行了大量的尝试来寻找最优策略。这些方法的关键在于缩小决策范围，加快决策进程。</p>
<p><strong>5)基于强化学习的方法</strong> 强化学习(RL)已广泛应用于微服务的资源管理。MIRAS[35]采用基于模型的RL方法进行决策，避免了真实环境的高采样复杂度。FIRM[4]利用支持向量机(SVM)识别微服务中的关键路径，并利用深度确定性策略梯度(DDPG)算法为路径上的微服务制定混合扩展策略。基于强化学习的方法需要在探索过程中不断与环境进行交互，并且无法适应动态微服务架构。</p>
<p>总之，尽管前面提到的自动缩放技术有各自的优势，但它们很少关注性能瓶颈。为非瓶颈微服务消耗计算机资源将不可避免地增加扩展成本和延长决策时间。另一方面，我们的方法侧重于定位性能瓶颈。</p>
<p><strong>3.System Design</strong></p>
<p>我们提出了PBScaler，一个以PB为中心的自动缩放控制器，用于定位PBs并优化它们的副本。如图4所示，PBScaler包括三个组件:</p>
<p>1)度量收集器:为了提供对应用程序状态的实时洞察，我们设计了一个度量收集器，它以固定的间隔从Prometheus4捕获并集成监视度量。</p>
<p>2)性能瓶颈分析:在度量收集器的帮助下，该组件执行SLO违规检测和冗余检查，以识别异常行为的微服务。接下来，瓶颈定位过程将被触发以精确定位异常微服务中的PBs。</p>
<p>3)缩放决策:该组件旨在使用进化算法确定PBs的最佳副本数量。最后，PBScaler生成具有优化策略的配置文件，并将其提交给kubernetes-client5, kubernetes-client5调节微服务的副本计数。</p>
<p><strong>3.1 Metric Collector</strong></p>
<p>自动伸缩系统依赖于对指标的实时访问，例如内存使用数据、系统负载和尾部延迟，以确定是否应该执行弹性伸缩以及应该在微服务应用程序中分配多少资源。与需要深入了解程序和代码注入的基于跟踪的监视器不同[7]，Metric Collector根据服务网格报告指标，以最大限度地减少对业务流的中断。如表1所示，PBScaler使用Prometheus和kube-state-metrics来收集和分类这些指标，包括<strong>响应延迟</strong>、微服务之间的<strong>调用关系</strong>、<strong>资源消耗</strong>和微服务<strong>工作负载</strong>。</p>
<p>![截屏2023-07-08 16.12.07](..&#x2F;images&#x2F;:Users:joshua:Library:Application Support:typora-user-images:截屏2023-07-08 16.12.07.png)</p>
<p>![截屏2023-07-08 16.15.24](..&#x2F;images&#x2F;:Users:joshua:Library:Application Support:typora-user-images:截屏2023-07-08 16.15.24.png)</p>
<p>例如，容器cpu使用秒总数是Prometheus中的一个标签，它记录了容器级别的中央处理单元(Central Processing Unit, cpu)使用情况。我们将Prometheus的监视间隔设置为5秒，并将收集到的指标数据存储在时间序列数据库中。每个微服务的P90尾部延迟被收集并用于表示应用程序的性能。调用关系暗示了微服务之间的关联，可用于构建微服务关联图。</p>
<p>服务网格Service Mesh</p>
<p>服务网格是一种基础设施，它使开发人员能够在不需要额外代码的情况下向云应用程序添加高级功能，如可观察性和流量管理。一个流行的开源服务网格实现是Istio7，旨在与Kubernetes无缝集成。当一个pod在Kubernetes中启动时，Istio在pod中启动一个特使代理来拦截网络流量，从而实现工作负载平衡和监控。</p>
<p><strong>3.2 Performance Bottleneck Analysis</strong></p>
<p>性能瓶颈分析(PBA)是一个旨在发现微服务应用程序中性能下降和资源浪费的过程，以推断当前问题的PBs。如第1节所述，通过准确定位这些瓶颈，PBA可以提高自动扩展的性能并减少过度的资源消耗。算法1描述了PBScaler中的PBA过程。</p>
<p>![截屏2023-07-09 14.19.35](..&#x2F;images&#x2F;:Users:joshua:Library:Application Support:typora-user-images:截屏2023-07-09 14.19.35.png)</p>
<p><strong>3.2.1 SLO Violation Detection</strong></p>
<p>为了检测微服务中的异常，PBScaler使用服务水平目标(slo)与特定指标进行比较。如果微服务有大量的SLO违规，即性能下降，则被认为是异常的。如[14]、[27]所述，检测违反SLO是触发瓶颈定位的关键步骤。可以利用Metric Collector收集的调用关系来构建微服务关联图Gc。PBScaler每15秒检查Gc中所有调用边的P90尾部延迟，以及时检测性能下降。如果调用的尾部延迟超过预定的阈值(如SLO)，则调用的被调用微服务将被添加到异常微服务集中，并且将激活瓶颈本地化过程。为了考虑微服务延迟中偶尔出现的噪声，阈值设置为slox (1 + α&#x2F;2)，其中α用于调整对噪声的容忍度</p>
<p><strong>3.2.2 Redundancy Checking</strong></p>
<p>在没有性能异常的情况下，一些微服务可能会被分配比所需更多的资源。然而，仅仅通过度量来识别这样的情况是很困难的，这可能会浪费有限的硬件资源。为了避免这种情况，有必要确定哪些微服务分配了多余的资源。PBScaler使用微服务每秒的工作负载变化率来确定资源是否冗余。</p>
<p>此策略比仅依赖资源消耗更有效，因为不同的微服务对异构资源的敏感性可能不同。冗余检查背后的主要思想是采用假设检验来检测微服务当前的工作负载wi c是否显著低于其过去的工作负载(表示为wi p)。显著程度通过参数βt来调整，假设检验可以表示为:</p>
<p>![截屏2023-07-09 14.18.53](..&#x2F;images&#x2F;:Users:joshua:Library:Application Support:typora-user-images:截屏2023-07-09 14.18.53.png)</p>
<p>为了执行假设检验，我们首先从Metric Collector获取目标微服务的当前和历史工作负载。然后我们使用单侧检验来计算p-value P。如果P不超过置信水平cl(默认设置为0.05)，我们拒绝零假设H0，并认为微服务i具有冗余资源。</p>
<p>![截屏2023-07-09 14.21.30](..&#x2F;images&#x2F;:Users:joshua:Library:Application Support:typora-user-images:截屏2023-07-09 14.21.30.png)</p>
<p><strong>3.2.3 Bottleneck Localisation</strong></p>
<p>由于微服务应用程序中复杂的交互[36]，并不是每个异常的微服务都需要扩展。例如，图5说明了瓶颈微服务(例如，Product)的性能下降如何沿着调用链传播到它的上游微服务(例如，recommendation, Frontend和Checkout)，即使上游微服务没有过载。因此，只有瓶颈微服务必须被扩展，而其他异常微服务只是被牵连。为了精确定位瓶颈微服务，我们引入了异常潜力的概念，它聚集了给定位置上所有微服务的异常影响。由于PB被许多受其影响的异常微服务所包围，因此PB的异常潜力通常很高。我们设计了一种新的瓶颈定位算法TopoRank，该算法在随机行走中引入拓扑势理论(TPT)来计算所有异常微服务的得分，并最终输出一个排名列表(rl)。在rl中得分最高的微服务可以被识别为PBs。</p>
<p>![截屏2023-07-09 14.25.11](..&#x2F;images&#x2F;:Users:joshua:Library:Application Support:typora-user-images:截屏2023-07-09 14.25.11.png)</p>
<p>TPT源于物理学中“场”的概念，在各种著作中被广泛应用[37]，[38]来衡量复杂网络中节点之间的相互影响。由于微服务关联图也可以被视为一个复杂的网络，我们使用TPT来评估微服务的异常潜力。具体来说，我们已经观察到，在微服务关联图Gc中，离PBs更近的微服务，即那些跳数较少的微服务，更有可能出现异常，因为它们经常频繁地直接或间接调用PBs。基于这一观察，我们使用TPT评估微服务的异常潜力。为此，我们首先通过识别异常微服务及其在Gc中的调用关系来提取异常子图Ga。然后，我们使用TPT计算异常子图Ga中微服务vi的拓扑势。</p>
<p>![截屏2023-07-09 14.26.52](..&#x2F;images&#x2F;:Users:joshua:Library:Application Support:typora-user-images:截屏2023-07-09 14.26.52.png)</p>
<p>N为vi的上游微服务数，mj为vj的异常程度。PBScaler将异常程度定义为微服务在一个时间窗口内违反SLO的次数。dji表示从vj到vi所需的最小跳数。我们使用影响因子σ来控制微服务的影响范围。</p>
<p>然而，具有高拓扑潜在值的微服务不一定是PBs，因为异常通常沿着微服务相关图传播。因此，单纯依靠TPT诊断PBs是不够的。为了解决这个问题，PBScaler结合了个性化PageRank算法[39]来逆转异常子图Ga上的异常传播并定位PBs。设P为Ga与Pi的转移矩阵，j为异常从vi跟踪到其下游节点vj的概率。给定输出度为d的vi，标准个性化PageRank算法将Pi,j集合为:</p>
<p>![截屏2023-07-09 14.29.14](..&#x2F;images&#x2F;:Users:joshua:Library:Application Support:typora-user-images:截屏2023-07-09 14.29.14.png)</p>
<p>这意味着该算法不会偏向于任何下游微服务。然而，这个定义没有考虑下游微服务和当前微服务异常之间的关联。因此，PBScaler通过更多地关注与上游响应时间更相关的下游微服务来调整计算。对于每个微服务vi, PBScaler收集尾部延迟序列(li)和一组度量数组Mi &#x3D; {m1, m2，···，mk}，其中mk可以被视为给定时间窗口内度量(例如，内存使用)的波动数组。PBScaler定义Pi,j取决于Mj中li与度量数组之间的Pearson相关系数的最大值:</p>
<p>![截屏2023-07-09 14.31.44](..&#x2F;images&#x2F;:Users:joshua:Library:Application Support:typora-user-images:截屏2023-07-09 14.31.44.png)</p>
<p>个性化PageRank算法通过在有向图上随机行走来确定每个节点的受欢迎程度。然而，一些节点可能永远不会指向其他节点，导致所有节点的分数在多次迭代后趋于零。为了避免落入这个“陷阱”，应用了一个阻尼因子δ，它允许算法根据预定义的规则从这些节点跳出来。通常δ设为0.15。个性化PageRank表示如下:</p>
<p>![截屏2023-07-09 14.33.44](..&#x2F;images&#x2F;:Users:joshua:Library:Application Support:typora-user-images:截屏2023-07-09 14.33.44.png)</p>
<p>其中v表示每个微服务节点被诊断为PB的概率。偏好向量u作为个性化规则，引导算法跳出陷阱。u的值由每个节点的异常势决定。异常潜力较大的节点优先作为算法的起始点。第k次迭代的方程可以表示为:</p>
<p>![截屏2023-07-09 14.34.19](..&#x2F;images&#x2F;:Users:joshua:Library:Application Support:typora-user-images:截屏2023-07-09 14.34.19.png)</p>
<p>经过多轮迭代，v逐渐收敛。PBScaler然后对最终结果进行排序并生成排名列表。排名列表得分最高的前k个微服务可以被识别为PBs。TopoRank的整个过程描述为算法2。</p>
<p><strong>3.3 Scaling Decision</strong></p>
<p>给定性能瓶颈分析确定的PBs，将对PBs的副本进行缩放，以最小化应用程序的资源消耗，同时确保微服务的端到端延迟符合SLO。尽管大量的副本可以缓解性能下降问题，但它们也会消耗大量的资源。因此，必须在性能保证和资源消耗之间保持平衡。缩放决策的过程将被建模为一个约束优化问题，以实现这种平衡。</p>
<p><strong>3.3.1 Constrained Optimation Model</strong></p>
<p>我们场景中的自动缩放优化试图确定一个分配模式，该模式为每个PB分配可变数量的副本。给定n个需要缩放的PBs，我们将策略定义为集合X &#x3D; {x1, x2，···，xn}，其中xi表示分配给pbi的副本数量。在优化之前，PBs的初始副本数量可以表示为C &#x3D; {c1, c2，···，cn}。应该注意的是，PBScaler中的副本约束应该分别为按比例缩小和按比例扩大的流程定义。在扩展过程中，我们对PBs的副本数量进行了如下限制:</p>
<p>![截屏2023-07-09 14.36.59](..&#x2F;images&#x2F;:Users:joshua:Library:Application Support:typora-user-images:截屏2023-07-09 14.36.59.png)</p>
<p>其中c^max表示给定有限的服务器资源，微服务可以扩展到的最大副本数量。在缩小过程中，副本数量的约束可以表示为:</p>
<p>![截屏2023-07-09 14.38.06](..&#x2F;images&#x2F;:Users:joshua:Library:Application Support:typora-user-images:截屏2023-07-09 14.38.06.png)</p>
<p>在Eq.(8,就是上面这个公示)中，γ(默认值为2)表示复制减少的最大数量。这个限制是合理的，因为正如在实验中观察到的那样，大幅减少微服务副本的数量可能会导致短暂的延迟峰值。</p>
<p>缩放决策的目标是尽量减少应用程序的资源消耗，同时保持其性能。应用程序性能通常用用户更关心的SLO违规来表示。因此，应用程序性能奖励可以细化为:</p>
<p>![截屏2023-07-09 14.40.23](..&#x2F;images&#x2F;:Users:joshua:Library:Application Support:typora-user-images:截屏2023-07-09 14.40.23.png)</p>
<p>在优化过程中，应用程序的资源消耗(如CPU和内存使用)是不可预测的。为了保守地估计资源消耗，我们考虑PB副本与可分配副本的最大数量的比率，而不是计算CPU和内存的成本。我们将资源奖励计算为:</p>
<p>![截屏2023-07-09 14.41.36](..&#x2F;images&#x2F;:Users:joshua:Library:Application Support:typora-user-images:截屏2023-07-09 14.41.36.png)</p>
<p>我们的目标是在保证性能的同时尽量减少资源消耗。我们利用加权线性组合(WLC)方法来平衡这两个目标。最终优化目标定义为:</p>
<p>![截屏2023-07-09 14.43.20](..&#x2F;images&#x2F;:Users:joshua:Library:Application Support:typora-user-images:截屏2023-07-09 14.43.20.png)</p>
<p>式中λ∈[0,1]。我们将λ设置为参数，以平衡应用程序性能和资源消耗。</p>
<p><strong>3.3.2 SLO Violation Predictor</strong></p>
<p>为了计算性能奖励R1，需要评估策略是否会导致在线应用程序违反SLO。一种简单的方法是直接在在线申请中执行候选策略，并等待监控系统的反馈。然而，在线应用程序中频繁缩放引起的振荡是不可避免的。另一种方法是使用历史度量数据训练评估模型，该模型可以模拟在线应用的反馈。在不与在线应用程序交互的情况下，该模型根据应用程序的当前状态预测应用程序的性能。</p>
<p>我们使用向量r来表示执行扩展策略x后每个微服务的副本数量。w是表示每个微服务当前工作负载的向量。由于瓶颈感知优化的时间成本较低，我们可以合理地假设w在此期间不会发生显著变化(参见4.2节)。给定由工作负载w和所有微服务副本r表示的应用状态，一个SLO违例预测器可以设计为:</p>
<p>![截屏2023-07-09 14.47.43](..&#x2F;images&#x2F;:Users:joshua:Library:Application Support:typora-user-images:截屏2023-07-09 14.47.43.png)</p>
<p>其中ψ是一个二元分类模型。选择合适的分类模型的细节将在4.3节中讨论。用于训练的历史度量数据可以使用经典缩放方法(默认是Kubernetes自动缩放器)或随机方法生成。我们在3个节点(共44个CPU核和220gb RAM)上部署了一个开源微服务系统，并进行了弹性扩展。普罗米修斯以固定的时间间隔收集每个微服务的工作负载和P90尾部延迟。通过比较前端微服务的尾部延迟和SLO，可以很容易地标记每个时间间隔的监控数据。</p>
<p>![截屏2023-07-09 14.48.39](..&#x2F;images&#x2F;:Users:joshua:Library:Application Support:typora-user-images:截屏2023-07-09 14.48.39.png)</p>
<p>Section 4.3。用于训练的历史度量数据可以使用经典缩放方法(默认是Kubernetes自动缩放器)或随机方法生成。我们在3个节点(共44个CPU核和220gb RAM)上部署了一个开源微服务系统，并进行了弹性扩展。普罗米修斯以固定的时间间隔收集每个微服务的工作负载和P90尾部延迟。通过比较前端微服务的尾部延迟和SLO，可以很容易地标记每个时间间隔的监控数据。</p>
<p><strong>3.3.3 Autoscaling Optimisation</strong></p>
<p>如第3.3.1节所述，性能和资源消耗之间的权衡可以建模为约束优化问题。为了找到接近最优的策略，PBScaler使用遗传算法(GA)来生成和优化扩展策略，以减少资源消耗，同时满足SLO要求。遗传算法通过模拟进化中的自然选择，在淘汰劣等子代的同时提高优等子代。首先，遗传算法执行随机搜索来初始化策略空间中的染色体种群，每条染色体表示优化问题的潜在策略。接下来，在每次迭代中，将选择具有高适应度的精英染色体(称为精英)进行交叉或突变以产生下一代。</p>
<p>我们场景中的自动缩放优化旨在确定一种缩放策略，该策略为每个PB分配可变数量的副本。自缩放优化过程如图6所示。一开始，PBScaler获得每个微服务当前的副本数量r和工作负载w。在性能瓶颈分析之后，PBScaler从r中识别PBs，并将它们过滤出来，得到r ‘。然后，决策者生成PBs策略的总体。由于要扩展的微服务数量会影响优化算法的速度和效果(第4.3节)，PBScaler假设只有PBs需要进行弹性扩展。换句话说，r ‘中的副本数量将保持不变。SLO违例预测器负责评估生成的策略。需要注意的是，该策略与r ‘合并，并与w一起输入到SLO违规预测器中。通过遗传算法选择优策略Xbest，并与r ‘合并，生成最终决策。</p>
<p>![截屏2023-07-09 14.41.12](..&#x2F;images&#x2F;:Users:joshua:Library:Application Support:typora-user-images:截屏2023-07-09 14.41.12.png)</p>
<p>在优化阶段，决策者使用遗传算法生成并改进PB的缩放策略，如算法3所述。在每个PB的策略范围内随机生成一个种群(第1行)后，Decision Maker根据Eq.(11)估计每个策略的适应度，并存储精英(第2-3行)。在每次迭代中，遗传算法使用基于锦标赛的选择算子来挑选优秀的亲本(第6行)。通过使用两个点交叉算子和双染色体突变算子，通过重组和突变(第7-8行)产生新的后代。通过模拟自然选择，新的后代和亲本精英形成一个新的种群，进入下一个迭代(第9行)。当遗传算法达到指定的迭代次数时，Decision Maker返回适应度最高的缩放决策Xbest。</p>
<p><strong>4 Evaluation</strong></p>
<p>在本节中，我们详细介绍了自动缩放的实验场景，包括PBScaler与学术界和工业界几种最先进的自动缩放算法的比较。</p>
<p><strong>4.1 Experimental Setup</strong></p>
<p><strong>4.1.1 Microserice Platform</strong></p>
<p>实验在我们的私有云集群中进行，该集群由三台物理计算机(一个主节点和两个工作节点)组成，共有44个Intel 2.40 GHz CPU内核和220gb RAM。为了评估自动扩展，我们选择了两个开源微服务应用程序作为基准:a)在线精品8，一个由谷歌开发的基于web的电子商务演示应用程序。该系统通过10个无状态微服务和Redis缓存的协作，实现了浏览产品、将商品添加到购物车和支付处理等基本功能。b) Train Ticket9:复旦大学开发的大型开源微服务系统。Train Ticket拥有40多个微服务，并使用MongoDB和MySQL进行数据存储，可以满足各种工作流程，如在线门票浏览，预订和购买。由于集群资源的限制，我们将每个微服务限制为不超过8个副本。源代码可在Github上获得.</p>
<p><strong>4.1.2 Workload</strong></p>
<p>我们评估了PBScaler在各种流量场景下的有效性，使用了2015年3月16日Wiki-Pageviews[40]的真实维基百科工作负载，以及受Abdullah等人[41]的实验启发的五种模拟工作负载(EW1 ~ EW5)。我们将实际工作负载压缩到一个小时，并将其扩展到适合我们集群的级别。五个模拟工作负载表现出不同的模式，例如单峰、多峰、上升和下降，并且持续时间限制为20分钟。图7描述了这些工作负载的波动情况。</p>
<p><strong>4.1.3 Baseline Metrics</strong></p>
<p>我们将PBScaler与学术界和工业界的几种最先进的微服务自动扩展方法进行比较，这些方法从静态阈值、控制理论和黑盒优化的角度执行微服务的动态水平扩展。</p>
<p>Kubernetes水平Pod自动缩放(<strong>KHPA</strong>):这是Kubernetes默认的水平缩放方案。通过为特定的资源R定制阈值T (CPU使用率为默认值)，并从微服务的所有副本中聚合资源使用URi, KHPA将副本的目标数量定义为</p>
<p>![截屏2023-07-09 15.19.46](..&#x2F;images&#x2F;:Users:joshua:Library:Application Support:typora-user-images:截屏2023-07-09 15.19.46.png)</p>
<p><strong>MicroScaler</strong>[15]:这是一个自动扩展工具，它使用黑盒优化算法来确定微服务的最佳副本数量。MicroScaler计算微服务的P90&#x2F;P50进行分类，然后执行贝叶斯优化的四次迭代来做出扩展决策。</p>
<p><strong>SHOWAR</strong>[11]:它是一种混合自缩放技术。我们在SHOWAR中再现了水平缩放部分，它使用PID控制理论使观察到的度量逐渐接近用户指定的阈值。在我们的实现中，我们用更常见的P90延迟替换了运行队列延迟，因为前者需要额外的eBPF工具。</p>
<p><strong>4.1.4 Experimental Parameters and Evaluation Criteria</strong></p>
<p>在我们的实验中，我们将普罗米修斯的收集间隔固定为5秒。随着实验时间和工作负载的增加，MongoDB等有状态微服务所需的数据量也会增加。最终，数据量将超过可用内存，从而需要使用磁盘存储。这种转换可能导致无法通过自动缩放来补救的性能下降。因此，我们将工作负载测试限制为无状态跟踪。在线精品店和火车票的SLO值分别设置为500毫秒和200毫秒。在SLO违例检测和冗余检查模块中，PBScaler首先将动作边界α设置为0.2，以减少噪声干扰。然后，我们根据经验将显著度β设置为0.9，以控制触发扩展的工作负载水平。对于瓶颈定位，将拓扑势的影响因子σ设为1，将rl中得分最高的top-k (k &#x3D;2)个微服务视为PBs。</p>
<p>我们选择了SLO违规率、资源消耗和响应时间来评估自缩放方法的性能。如果自动缩放方法可以减少响应时间、SLO违规率和资源消耗，则认为它更有效。我们将SLO违例率定义为端到端P90尾部延迟超过SLO的百分比。资源消耗按照[42]给出的方法计算，其中CPU价格为0.00003334$ (vCPU&#x2F;s)，内存价格为0.00001389$ (G&#x2F;s)。总资源消耗由内存成本和CPU成本相加得到。</p>
<p>![截屏2023-07-09 15.23.18](..&#x2F;images&#x2F;:Users:joshua:Library:Application Support:typora-user-images:截屏2023-07-09 15.23.18.png)</p>
<p>![截屏2023-07-09 15.24.13](..&#x2F;images&#x2F;:Users:joshua:Library:Application Support:typora-user-images:截屏2023-07-09 15.24.13.png)</p>
<p><strong>4.2 Performance Evaluation</strong></p>
<p>表2比较了具有不同工作负载的两个微服务应用程序中四种自动伸缩方法的SLO违反率和资源成本。None方法用作引用，不执行自动缩放操作。其结果以灰色表示，并被排除在比较之外。</p>
<p>![截屏2023-07-09 15.25.47](..&#x2F;images&#x2F;:Users:joshua:Library:Application Support:typora-user-images:截屏2023-07-09 15.25.47.png)</p>
<p>一般来说，PBScaler在减少两个微服务系统中六个工作负载下的SLO违规和最小化资源开销方面优于其他竞争方法。其中，PBScaler在火车票中的SLO违规率比基线方法平均降低4.96%，资源成本平均降低0.24美元。结果表明，PBScaler可以快速、精确地对大规模微服务系统中的瓶颈微服务进行弹性扩展，从而减少了SLO违规，节省了资源。对于Online Boutique中的6个工作负载，PBScaler还在其中4个模拟工作负载中实现了最低的SLO违规，并在3个模拟工作负载中实现了最低的资源消耗。</p>
<p>图8描绘了六种工作负载下不同方法的延迟分布箱形图，探讨了每种方法对微服务系统性能的影响。可以看出，大多数自动缩放方法都可以保持延迟分布的中位数低于红色虚线(SLO)。但是，只有PBScaler进一步将第三个四分位数降低到所有工作负载的SLO以下。</p>
<p>为了评估使用PBScaler进行弹性缩放的时间成本，收集并计算了PBScaler中每个模块所需的平均时间。如表3所示，Online Boutique中所有PBScaler模块的总时间成本小于一个监控间隔(即5s)，而Train Ticket的相同度量小于两个监控间隔。由于PBA缩小了决策范围，当应用程序从Online Boutique切换到Train Ticket时，尽管微服务的数量增加了，但决策者的时间成本并没有增加太多(不超过6.6%)。然而，我们认识到随着微服务规模的增长，PBA的时间消耗会迅速增加，这将是我们未来的工作。</p>
<p>![截屏2023-07-09 15.29.10](..&#x2F;images&#x2F;:Users:joshua:Library:Application Support:typora-user-images:截屏2023-07-09 15.29.10.png)</p>
<p>![截屏2023-07-09 15.29.50](..&#x2F;images&#x2F;:Users:joshua:Library:Application Support:typora-user-images:截屏2023-07-09 15.29.50.png)</p>
<p><strong>4.3 Effectiveness Analysis of Components</strong></p>
<p><strong>4.3.1 Performance Comparision of Bottleneck Localization</strong></p>
<p>为了评估TopoRank算法是否能有效定位突发工作负载引起的PBs，我们通过Chaos Mesh将CPU过载、内存溢出和网络拥塞等异常注入到Online Boutique和Train Ticket中。这些异常通常是由高工作负载条件引起的。使用TopoRank算法分析度量并确定这些异常的性能瓶颈。然后将定位结果与micrororca[27]进行比较，micrororca是微服务根本原因分析的基线方法。AC@k测量前k个结果中实际PBs的精度，Avg@k是前k个结果的平均精度。这些指标的计算方法如下。A表示微服务的集合，RT@k表示排名列表中排名前k的微服务。</p>
<p>![截屏2023-07-09 15.32.15](..&#x2F;images&#x2F;:Users:joshua:Library:Application Support:typora-user-images:截屏2023-07-09 15.32.15.png)</p>
<p>图9给出了TopoRank和MicroRCA在不同微服务应用中的AC@1和Avg@5值。结果表明，TopoRank在这两个指标上都优于MicroRCA。这主要是由于TopoRank在执行个性化PageRank时考虑了异常可能性和微服务依赖关系。</p>
<p>瓶颈定位的主要目的是缩小策略空间，加快最优策略的发现。我们在PBs和所有微服务上执行遗传算法迭代，以证明瓶颈定位对优化的影响。图10描述了微服务系统下的迭代过程，并表明随着人口(Pop)的增加，pb感知策略在适应度方面明显优于适用于所有微服务的方法。该策略可以在不到5次迭代中获得较好的适应度。相比之下，涉及所有微服务的方法需要更大的种群和更多的迭代才能达到相同的适应度水平。这是由于pb感知策略帮助遗传算法精确地缩小了优化范围，加速了优解的获取。</p>
<p><strong>4.3.2 Effectiveness of the SLO Violation Predictor</strong></p>
<p>SLO违例预测器的目标是直接预测优化策略的结果，而不是等待在线应用程序的反馈。我们根据每个微服务的副本数量和工作负载来确定是否会出现性能问题。为预测任务选择合适的二分类模型至关重要。以5秒的数据收集间隔，我们在我们的集群中收集了两个数据集，包括3.1k的火车票历史采样数据集(a)和1.5k的在线精品数据集(B)。为了对这两个数据集进行训练和测试，我们采用了四种经典的机器学习方法，包括支持向量机(SVM)、随机森林(Random Forest)、多层感知器(Multilayer Perceptron)和决策树(Decision Tree)。表4给出了四种模型对SLO违规预测的准确率和召回率。根据两个数据集的效果，我们最终选择随机森林作为SLO违例预测的主要算法。</p>
<p>为了证明SLO违例预测器可以替代来自真实环境的反馈，我们将使用SLO违例预测器的PBScaler与从在线系统收集反馈的MicroScaler进行了比较。我们将突发工作负载注入Online Boutique，并仅使一个微服务异常，以消除两种方法在瓶颈定位方面的差异。如图11所示，在预测器的引导下，PBScaler的决策尝试次数和频率远低于MicroScaler。减少集群中的在线尝试将明显降低振荡的风险。</p>
<p><strong>5 Conclusion</strong></p>
<p>本文介绍了PBScaler，一个瓶颈感知自动伸缩框架，旨在防止基于微服务的应用程序的性能退化。PBScaler使用服务网格技术收集应用程序的实时性能指标，并动态构建微服务之间的关联图。为了处理由外部动态工作负载和微服务之间复杂调用引起的微服务异常，PBScaler采用基于拓扑势理论的随机游动算法TopoRank来识别瓶颈微服务。此外，PBScaler采用离线进化算法，在SLO违规预测器的指导下优化缩放策略。实验结果表明，PBScaler可以在最小化资源消耗的同时实现较低的SLO违规。在未来，我们计划从以下两个方面改进我们的工作。首先，我们将探索在细粒度资源(例如，CPU和内存)管理中使用瓶颈感知的潜力。其次，我们将探讨如何规避自扩展中有状态微服务的干扰，因为有状态微服务的性能下降可能会破坏自扩展控制器。第三，提高大规模微服务系统性能瓶颈分析的效率。</p>
 
      <!-- reward -->
      
      <div id="reword-out">
        <div id="reward-btn">
          Donate
        </div>
      </div>
      
    </div>
    

    <!-- copyright -->
    
    <div class="declare">
      <ul class="post-copyright">
        <li>
          <i class="ri-copyright-line"></i>
          <strong>Copyright： </strong>
          
          Copyright is owned by the author. For commercial reprints, please contact the author for authorization. For non-commercial reprints, please indicate the source.
          
        </li>
      </ul>
    </div>
    
    <footer class="article-footer">
       
<div class="share-btn">
      <span class="share-sns share-outer">
        <i class="ri-share-forward-line"></i>
        Share
      </span>
      <div class="share-wrap">
        <i class="arrow"></i>
        <div class="share-icons">
          
          <a class="weibo share-sns" href="javascript:;" data-type="weibo">
            <i class="ri-weibo-fill"></i>
          </a>
          <a class="weixin share-sns wxFab" href="javascript:;" data-type="weixin">
            <i class="ri-wechat-fill"></i>
          </a>
          <a class="qq share-sns" href="javascript:;" data-type="qq">
            <i class="ri-qq-fill"></i>
          </a>
          <a class="douban share-sns" href="javascript:;" data-type="douban">
            <i class="ri-douban-line"></i>
          </a>
          <!-- <a class="qzone share-sns" href="javascript:;" data-type="qzone">
            <i class="icon icon-qzone"></i>
          </a> -->
          
          <a class="facebook share-sns" href="javascript:;" data-type="facebook">
            <i class="ri-facebook-circle-fill"></i>
          </a>
          <a class="twitter share-sns" href="javascript:;" data-type="twitter">
            <i class="ri-twitter-fill"></i>
          </a>
          <a class="google share-sns" href="javascript:;" data-type="google">
            <i class="ri-google-fill"></i>
          </a>
        </div>
      </div>
</div>

<div class="wx-share-modal">
    <a class="modal-close" href="javascript:;"><i class="ri-close-circle-line"></i></a>
    <p>扫一扫，分享到微信</p>
    <div class="wx-qrcode">
      <img src="//api.qrserver.com/v1/create-qr-code/?size=150x150&data=http://example.com/2023/06/19/project-notes/" alt="微信分享二维码">
    </div>
</div>

<div id="share-mask"></div>  
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Courses/" rel="tag">Courses</a></li></ul>

    </footer>
  </div>

   
  <nav class="article-nav">
    
      <a href="/2023/06/26/kubernetes/" class="article-nav-link">
        <strong class="article-nav-caption">Previous Post</strong>
        <div class="article-nav-title">
          
            kubernetes
          
        </div>
      </a>
    
    
      <a href="/2023/06/17/docker/" class="article-nav-link">
        <strong class="article-nav-caption">Next Post</strong>
        <div class="article-nav-title">docker</div>
      </a>
    
  </nav>

  
   
    
    <script src="https://cdn.staticfile.org/twikoo/1.4.18/twikoo.all.min.js"></script>
    <div id="twikoo" class="twikoo"></div>
    <script>
        twikoo.init({
            envId: ""
        })
    </script>
 
</article>

</section>
      <footer class="footer">
  <div class="outer">
    <ul>
      <li>
        Copyrights &copy;
        2021-2023
        <i class="ri-heart-fill heart_icon"></i> Mingwei Li
      </li>
    </ul>
    <ul>
      <li>
        
      </li>
    </ul>
    <ul>
      <li>
        
        
        <span>
  <span><i class="ri-user-3-fill"></i>Visitors:<span id="busuanzi_value_site_uv"></span></span>
  <span class="division">|</span>
  <span><i class="ri-eye-fill"></i>Views:<span id="busuanzi_value_page_pv"></span></span>
</span>
        
      </li>
    </ul>
    <ul>
      
    </ul>
    <ul>
      
    </ul>
    <ul>
      <li>
        <!-- cnzz统计 -->
        
        <script type="text/javascript" src='https://s9.cnzz.com/z_stat.php?id=1278069914&amp;web_id=1278069914'></script>
        
      </li>
    </ul>
  </div>
</footer>    
    </main>
    <div class="float_btns">
      <div class="totop" id="totop">
  <i class="ri-arrow-up-line"></i>
</div>

<div class="todark" id="todark">
  <i class="ri-moon-line"></i>
</div>

    </div>
    <aside class="sidebar on">
      <button class="navbar-toggle"></button>
<nav class="navbar">
  
  <div class="logo">
    <a href="/"><img src="/images/ayer-side.svg" alt="Mingwei’s Blog"></a>
  </div>
  
  <ul class="nav nav-main">
    
    <li class="nav-item">
      <a class="nav-item-link" href="/">Home</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/archives">Archives</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/categories">Categories</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags">Tags</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" target="_blank" rel="noopener" href="http://shenyu-vip.lofter.com">Gallery</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags/travel">Travel</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/2019/about">About</a>
    </li>
    
  </ul>
</nav>
<nav class="navbar navbar-bottom">
  <ul class="nav">
    <li class="nav-item">
      
      <a class="nav-item-link nav-item-search"  title="Search">
        <i class="ri-search-line"></i>
      </a>
      
      
      <a class="nav-item-link" target="_blank" href="/atom.xml" title="RSS Feed">
        <i class="ri-rss-line"></i>
      </a>
      
    </li>
  </ul>
</nav>
<div class="search-form-wrap">
  <div class="local-search local-search-plugin">
  <input type="search" id="local-search-input" class="local-search-input" placeholder="Search...">
  <div id="local-search-result" class="local-search-result"></div>
</div>
</div>
    </aside>
    <div id="mask"></div>

<!-- #reward -->
<div id="reward">
  <span class="close"><i class="ri-close-line"></i></span>
  <p class="reward-p"><i class="ri-cup-line"></i>请我喝杯咖啡吧~</p>
  <div class="reward-box">
    
    <div class="reward-item">
      <img class="reward-img" src="/images/alipay.jpg">
      <span class="reward-type">支付宝</span>
    </div>
    
    
    <div class="reward-item">
      <img class="reward-img" src="/images/wechat.jpg">
      <span class="reward-type">微信</span>
    </div>
    
  </div>
</div>
    
<script src="/js/jquery-3.6.0.min.js"></script>
 
<script src="/js/lazyload.min.js"></script>

<!-- Tocbot -->
 
<script src="/js/tocbot.min.js"></script>

<script>
  tocbot.init({
    tocSelector: ".tocbot",
    contentSelector: ".article-entry",
    headingSelector: "h1, h2, h3, h4, h5, h6",
    hasInnerContainers: true,
    scrollSmooth: true,
    scrollContainer: "main",
    positionFixedSelector: ".tocbot",
    positionFixedClass: "is-position-fixed",
    fixedSidebarOffset: "auto",
  });
</script>

<script src="https://cdn.staticfile.org/jquery-modal/0.9.2/jquery.modal.min.js"></script>
<link
  rel="stylesheet"
  href="https://cdn.staticfile.org/jquery-modal/0.9.2/jquery.modal.min.css"
/>
<script src="https://cdn.staticfile.org/justifiedGallery/3.8.1/js/jquery.justifiedGallery.min.js"></script>

<script src="/dist/main.js"></script>

<!-- ImageViewer -->
 <!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>

<link rel="stylesheet" href="https://cdn.staticfile.org/photoswipe/4.1.3/photoswipe.min.css">
<link rel="stylesheet" href="https://cdn.staticfile.org/photoswipe/4.1.3/default-skin/default-skin.min.css">
<script src="https://cdn.staticfile.org/photoswipe/4.1.3/photoswipe.min.js"></script>
<script src="https://cdn.staticfile.org/photoswipe/4.1.3/photoswipe-ui-default.min.js"></script>

<script>
    function viewer_init() {
        let pswpElement = document.querySelectorAll('.pswp')[0];
        let $imgArr = document.querySelectorAll(('.article-entry img:not(.reward-img)'))

        $imgArr.forEach(($em, i) => {
            $em.onclick = () => {
                // slider展开状态
                // todo: 这样不好，后面改成状态
                if (document.querySelector('.left-col.show')) return
                let items = []
                $imgArr.forEach(($em2, i2) => {
                    let img = $em2.getAttribute('data-idx', i2)
                    let src = $em2.getAttribute('data-target') || $em2.getAttribute('src')
                    let title = $em2.getAttribute('alt')
                    // 获得原图尺寸
                    const image = new Image()
                    image.src = src
                    items.push({
                        src: src,
                        w: image.width || $em2.width,
                        h: image.height || $em2.height,
                        title: title
                    })
                })
                var gallery = new PhotoSwipe(pswpElement, PhotoSwipeUI_Default, items, {
                    index: parseInt(i)
                });
                gallery.init()
            }
        })
    }
    viewer_init()
</script> 
<!-- MathJax -->

<!-- Katex -->

<!-- busuanzi  -->
 
<script src="/js/busuanzi-2.3.pure.min.js"></script>
 
<!-- ClickLove -->

<!-- ClickBoom1 -->

<!-- ClickBoom2 -->

<!-- CodeCopy -->
 
<link rel="stylesheet" href="/css/clipboard.css">
 <script src="https://cdn.staticfile.org/clipboard.js/2.0.10/clipboard.min.js"></script>
<script>
  function wait(callback, seconds) {
    var timelag = null;
    timelag = window.setTimeout(callback, seconds);
  }
  !function (e, t, a) {
    var initCopyCode = function(){
      var copyHtml = '';
      copyHtml += '<button class="btn-copy" data-clipboard-snippet="">';
      copyHtml += '<i class="ri-file-copy-2-line"></i><span>COPY</span>';
      copyHtml += '</button>';
      $(".highlight .code pre").before(copyHtml);
      $(".article pre code").before(copyHtml);
      var clipboard = new ClipboardJS('.btn-copy', {
        target: function(trigger) {
          return trigger.nextElementSibling;
        }
      });
      clipboard.on('success', function(e) {
        let $btn = $(e.trigger);
        $btn.addClass('copied');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-checkbox-circle-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPIED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-checkbox-circle-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
      clipboard.on('error', function(e) {
        e.clearSelection();
        let $btn = $(e.trigger);
        $btn.addClass('copy-failed');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-time-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPY FAILED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-time-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
    }
    initCopyCode();
  }(window, document);
</script>
 
<!-- CanvasBackground -->

<script>
  if (window.mermaid) {
    mermaid.initialize({ theme: "forest" });
  }
</script>


    
    

  </div>
</body>

</html>